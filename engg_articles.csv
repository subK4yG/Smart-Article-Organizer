title,authors,abstract,url,keywords,category,citations,publication
MetaScale: Test-Time Scaling with Evolving Meta-Thoughts,"Qin Liu, Wenxuan Zhou, Nan Xu, James Y. Huang, Fei Wang, Sheng Zhang, Hoifung Poon, Muhao Chen","One critical challenge for large language models (LLMs) for making complex reasoning is their reliance on matching reasoning patterns from training data, instead of proactively selecting the most appropriate cognitive strategy to solve a given task. Existing approaches impose fixed cognitive structures that enhance performance in specific tasks but lack adaptability across diverse scenarios. To address this limitation, we introduce METASCALE, a test-time scaling framework based on meta-thoughts -- adaptive thinking strategies tailored to each task. METASCALE initializes a pool of candidate meta-thoughts, then iteratively selects and evaluates them using a multi-armed bandit algorithm with upper confidence bound selection, guided by a reward model. To further enhance adaptability, a genetic algorithm evolves high-reward meta-thoughts, refining and extending the strategy pool over time. By dynamically proposing and optimizing meta-thoughts at inference time, METASCALE improves both accuracy and generalization across a wide range of tasks. Experimental results demonstrate that MetaScale consistently outperforms standard inference approaches, achieving an 11% performance gain in win rate on Arena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably, METASCALE scales more effectively with increasing sampling budgets and produces more structured, expert-level responses.",http://arxiv.org/abs/2503.13447v1,"models, challenge, reasoning, llms, language","Machine Learning & AI in Quantum, Quantum Machine Learning",870,2023
"Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance","Noah Y. Siegel, Nicolas Heess, Maria Perez-Ortiz, Oana-Maria Camburu","As large language models (LLMs) become increasingly capable, ensuring that their self-generated explanations are faithful to their internal decision-making process is critical for safety and oversight. In this work, we conduct a comprehensive counterfactual faithfulness analysis across 62 models from 8 families, encompassing both pretrained and instruction-tuned variants and significantly extending prior studies of counterfactual tests. We introduce phi-CCT, a simplified variant of the Correlational Counterfactual Test, which avoids the need for token probabilities while explaining most of the variance of the original test. Our findings reveal clear scaling trends: larger models are consistently more faithful on our metrics. However, when comparing instruction-tuned and human-imitated explanations, we find that observed differences in faithfulness can often be attributed to explanation verbosity, leading to shifts along the true-positive/false-positive Pareto frontier. While instruction-tuning and prompting can influence this trade-off, we find limited evidence that they fundamentally expand the frontier of explanatory faithfulness beyond what is achievable with pretrained models of comparable size. Our analysis highlights the nuanced relationship between instruction-tuning, verbosity, and the faithful representation of model decision processes.",http://arxiv.org/abs/2503.13445v1,"models, explanations, llms, self, language",Machine Learning & AI in Quantum,3782,2004
VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning,"Ye Liu, Kevin Qinghong Lin, Chang Wen Chen, Mike Zheng Shou","Videos, with their unique temporal dimension, demand precise grounded understanding, where answers are directly linked to visual, interpretable evidence. Despite significant breakthroughs in reasoning capabilities within Large Language Models, multi-modal reasoning - especially for videos - remains unexplored. In this work, we introduce VideoMind, a novel video-language agent designed for temporal-grounded video understanding. VideoMind incorporates two key innovations: (i) We identify essential capabilities for video temporal reasoning and develop a role-based agentic workflow, including a planner for coordinating different roles, a grounder for temporal localization, a verifier to assess temporal interval accuracy, and an answerer for question-answering. (ii) To efficiently integrate these diverse roles, we propose a novel Chain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA adaptors while avoiding the overhead of multiple models, thus balancing efficiency and flexibility. Extensive experiments on 14 public benchmarks demonstrate that our agent achieves state-of-the-art performance on diverse video understanding tasks, including 3 on grounded video question-answering, 6 on video temporal grounding, and 5 on general video question-answering, underscoring its effectiveness in advancing video agent and long-form temporal reasoning.",http://arxiv.org/abs/2503.13444v1,"understanding, answers, evidence, videos, dimension",Machine Learning & AI in Quantum,3102,2002
Humanoid Policy ~ Human Policy,"Ri-Zhao Qiu, Shiqi Yang, Xuxin Cheng, Chaitanya Chawla, Jialong Li, Tairan He, Ge Yan, Lars Paulsen, Ge Yang, Sha Yi, Guanya Shi, Xiaolong Wang","Training manipulation policies for humanoid robots with diverse data enhances their robustness and generalization across tasks and platforms. However, learning solely from robot demonstrations is labor-intensive, requiring expensive tele-operated data collection which is difficult to scale. This paper investigates a more scalable data source, egocentric human demonstrations, to serve as cross-embodiment training data for robot learning. We mitigate the embodiment gap between humanoids and humans from both the data and modeling perspectives. We collect an egocentric task-oriented dataset (PH2D) that is directly aligned with humanoid manipulation demonstrations. We then train a human-humanoid behavior policy, which we term Human Action Transformer (HAT). The state-action space of HAT is unified for both humans and humanoid robots and can be differentiably retargeted to robot actions. Co-trained with smaller-scale robot data, HAT directly models humanoid robots and humans as different embodiments without additional supervision. We show that human data improves both generalization and robustness of HAT with significantly better data collection efficiency. Code and data: https://human-as-robot.github.io/",http://arxiv.org/abs/2503.13441v1,"data, policies, robots, manipulation, training",Machine Learning & AI in Quantum,476,2011
Deep Belief Markov Models for POMDP Inference,"Giacomo Arcieri, Konstantinos G. Papakonstantinou, Daniel Straub, Eleni Chatzi","This work introduces a novel deep learning-based architecture, termed the Deep Belief Markov Model (DBMM), which provides efficient, model-formulation agnostic inference in Partially Observable Markov Decision Process (POMDP) problems. The POMDP framework allows for modeling and solving sequential decision-making problems under observation uncertainty. In complex, high-dimensional, partially observable environments, existing methods for inference based on exact computations (e.g., via Bayes' theorem) or sampling algorithms do not scale well. Furthermore, ground truth states may not be available for learning the exact transition dynamics. DBMMs extend deep Markov models into the partially observable decision-making framework and allow efficient belief inference entirely based on available observation data via variational inference methods. By leveraging the potency of neural networks, DBMMs can infer and simulate non-linear relationships in the system dynamics and naturally scale to problems with high dimensionality and discrete or continuous variables. In addition, neural network parameters can be dynamically updated efficiently based on data availability. DBMMs can thus be used to infer a belief variable, thus enabling the derivation of POMDP solutions over the belief space. We evaluate the efficacy of the proposed methodology by evaluating the capability of model-formulation agnostic inference of DBMMs in benchmark problems that include discrete and continuous variables.",http://arxiv.org/abs/2503.13438v1,"belief, learning, architecture, deep, work","Quantum Machine Learning, Machine Learning & AI in Quantum",4436,2007
Can Yang-Baxter imply Lie algebra?,"Dmitry Khudoteplov, Alexei Morozov, Alexey Sleptsov","Quantum knot invariants (like colored HOMFLY-PT or Kauffman polynomials) are a distinguished class of non-perturbative topological invariants. Any known way to construct them (via Chern-Simons theory or quantum R-matrix) starts with a finite simple Lie algebra. Another set of knot invariants - of finite type - is related to quantum invariants via a perturbative expansion. However can all finite type invariants be obtained in this way? Investigating this problem, P. Vogel discovered a way to polynomially parameterize the expansion coefficients with three parameters so that, at different specific values, this reproduces the answers for all simple Lie (super)algebras. Then it is easy to construct a polynomial $P_{alg}$ that vanishes for all simple Lie algebras, and the corresponding Vassiliev invariant would thus be absent from the perturbative expansion.   We review these Vogel claims pointing out at least two interesting implications of his construction. First, we discuss whether infinite-dimensional Lie algebras might enlarge Chern-Simons theory. Second, Vogel's construction implies an alternative axiomatization of simple Lie algebras - when we start from knot invariants and arrive at Lie algebras and their classification, which is opposite to conventional logic that we mentioned at the beginning.",http://arxiv.org/abs/2503.13437v1,"knot, pt, homfly, invariants, quantum",Mathematical & Theoretical Quantum Physics,3454,2021
Unified Autoregressive Visual Generation and Understanding with Continuous Tokens,"Lijie Fan, Luming Tang, Siyang Qin, Tianhong Li, Xuan Yang, Siyuan Qiao, Andreas Steiner, Chen Sun, Yuanzhen Li, Tao Zhu, Michael Rubinstein, Michalis Raptis, Deqing Sun, Radu Soricut","We present UniFluid, a unified autoregressive framework for joint visual generation and understanding leveraging continuous visual tokens. Our unified autoregressive architecture processes multimodal image and text inputs, generating discrete tokens for text and continuous tokens for image. We find though there is an inherent trade-off between the image generation and understanding task, a carefully tuned training recipe enables them to improve each other. By selecting an appropriate loss balance weight, the unified model achieves results comparable to or exceeding those of single-task baselines on both tasks. Furthermore, we demonstrate that employing stronger pre-trained LLMs and random-order generation during training is important to achieve high-fidelity image generation within this unified framework. Built upon the Gemma model series, UniFluid exhibits competitive performance across both image generation and understanding, demonstrating strong transferability to various downstream tasks, including image editing for generation, as well as visual captioning and question answering for understanding.",http://arxiv.org/abs/2503.13436v1,"understanding, generation, tokens, framework, unifluid",Quantum Machine Learning,3181,2002
BlobCtrl: A Unified and Flexible Framework for Element-level Image Generation and Editing,"Yaowei Li, Lingen Li, Zhaoyang Zhang, Xiaoyu Li, Guangzhi Wang, Hongxiang Li, Xiaodong Cun, Ying Shan, Yuexian Zou","Element-level visual manipulation is essential in digital content creation, but current diffusion-based methods lack the precision and flexibility of traditional tools. In this work, we introduce BlobCtrl, a framework that unifies element-level generation and editing using a probabilistic blob-based representation. By employing blobs as visual primitives, our approach effectively decouples and represents spatial location, semantic content, and identity information, enabling precise element-level manipulation. Our key contributions include: 1) a dual-branch diffusion architecture with hierarchical feature fusion for seamless foreground-background integration; 2) a self-supervised training paradigm with tailored data augmentation and score functions; and 3) controllable dropout strategies to balance fidelity and diversity. To support further research, we introduce BlobData for large-scale training and BlobBench for systematic evaluation. Experiments show that BlobCtrl excels in various element-level manipulation tasks while maintaining computational efficiency, offering a practical solution for precise and flexible visual content creation. Project page: https://liyaowei-stu.github.io/project/BlobCtrl/",http://arxiv.org/abs/2503.13434v1,"content, level, manipulation, element, creation",Machine Learning & AI in Quantum,2929,2000
Uncovering Utility Functions from Observed Outcomes,Marta Grzeskiewicz,"Determining consumer preferences and utility is a foundational challenge in economics. They are central in determining consumer behaviour through the utility-maximising consumer decision-making process. However, preferences and utilities are not observable and may not even be known to the individual making the choice; only the outcome is observed in the form of demand. Without the ability to observe the decision-making mechanism, demand estimation becomes a challenging task and current methods fall short due to lack of scalability or ability to identify causal effects. Estimating these effects is critical when considering changes in policy, such as pricing, the impact of taxes and subsidies, and the effect of a tariff. To address the shortcomings of existing methods, we combine revealed preference theory and inverse reinforcement learning to present a novel algorithm, Preference Extraction and Reward Learning (PEARL) which, to the best of our knowledge, is the only algorithm that can uncover a representation of the utility function that best rationalises observed consumer choice data given a specified functional form. We introduce a flexible utility function, the Input-Concave Neural Network which captures complex relationships across goods, including cross-price elasticities. Results show PEARL outperforms the benchmark on both noise-free and noisy synthetic data.",http://arxiv.org/abs/2503.13432v1,"economics, challenge, consumer, preferences, utility",Quantum Machine Learning,140,2002
Measuring In-Context Computation Complexity via Hidden State Prediction,"Vincent Herrmann, R?bert Csord?s, J?rgen Schmidhuber","Detecting when a neural sequence model does ""interesting"" computation is an open problem. The next token prediction loss is a poor indicator: Low loss can stem from trivially predictable sequences that are uninteresting, while high loss may reflect unpredictable but also irrelevant information that can be ignored by the model. We propose a better metric: measuring the model's ability to predict its own future hidden states. We show empirically that this metric -- in contrast to the next token prediction loss -- correlates with the intuitive interestingness of the task. To measure predictability, we introduce the architecture-agnostic ""prediction of hidden states"" (PHi) layer that serves as an information bottleneck on the main pathway of the network (e.g., the residual stream in Transformers). We propose a novel learned predictive prior that enables us to measure the novel information gained in each computation step, which serves as our metric. We show empirically that our metric predicts the description length of formal languages learned in-context, the complexity of mathematical reasoning problems, and the correctness of self-generated reasoning chains.",http://arxiv.org/abs/2503.13431v1,"prediction, computation, sequence, problem, model",Quantum Machine Learning,1695,2004
AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction,"Thomas Monninger, Md Zafar Anwar, Stanislaw Antol, Steffen Staab, Sihao Ding","Autonomous driving requires an understanding of the infrastructure elements, such as lanes and crosswalks. To navigate safely, this understanding must be derived from sensor data in real-time and needs to be represented in vectorized form. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set of camera images from multiple views into one joint latent BEV grid. Traditionally, from this latent space, an intermediate raster map is predicted, providing dense spatial supervision but requiring post-processing into the desired vectorized form. More recent models directly derive infrastructure elements as polylines using vectorized map decoders, providing instance-level information. Our approach, Augmentation Map Network (AugMapNet), proposes latent BEV grid augmentation, a novel technique that significantly enhances the latent BEV representation. AugMapNet combines vector decoding and dense spatial supervision more effectively than existing architectures while remaining as straightforward to integrate and as generic as auxiliary supervision. Experiments on nuScenes and Argoverse2 datasets demonstrate significant improvements in vectorized map prediction performance up to 13.3% over the StreamMapNet baseline on 60m range and greater improvements on larger ranges. We confirm transferability by applying our method to another baseline and find similar improvements. A detailed analysis of the latent BEV grid confirms a more structured latent space of AugMapNet and shows the value of our novel concept beyond pure performance improvement. The code will be released soon.",http://arxiv.org/abs/2503.13430v1,"understanding, driving, infrastructure, lanes, elements","Machine Learning & AI in Quantum, Quantum Machine Learning",779,2014
xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference,"Maximilian Beck, Korbinian P?ppel, Phillip Lippe, Richard Kurle, Patrick M. Blies, G?nter Klambauer, Sebastian B?ck, Sepp Hochreiter","Recent breakthroughs in solving reasoning, math and coding problems with Large Language Models (LLMs) have been enabled by investing substantial computation budgets at inference time. Therefore, inference speed is one of the most critical properties of LLM architectures, and there is a growing need for LLMs that are efficient and fast at inference. Recently, LLMs built on the xLSTM architecture have emerged as a powerful alternative to Transformers, offering linear compute scaling with sequence length and constant memory usage, both highly desirable properties for efficient inference. However, such xLSTM-based LLMs have yet to be scaled to larger models and assessed and compared with respect to inference speed and efficiency. In this work, we introduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's architectural benefits with targeted optimizations for fast and efficient inference. Our experiments demonstrate that xLSTM 7B achieves performance on downstream tasks comparable to other similar-sized LLMs, while providing significantly faster inference speeds and greater efficiency compared to Llama- and Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most efficient 7B LLM, offering a solution for tasks that require large amounts of test-time computation. Our work highlights xLSTM's potential as a foundational architecture for methods building on heavy use of LLM inference. Our model weights, model code and training code are open-source.",http://arxiv.org/abs/2503.13427v1,"math, breakthroughs, reasoning, problems, large","Quantum Machine Learning, Machine Learning & AI in Quantum",2401,2013
SuperBPE: Space Travel for Language Models,"Alisa Liu, Jonathan Hayase, Valentin Hofmann, Sewoong Oh, Noah A. Smith, Yejin Choi","The assumption across nearly all language model (LM) tokenization schemes is that tokens should be subwords, i.e., contained within word boundaries. While providing a seemingly reasonable inductive bias, is this common practice limiting the potential of modern LMs? Whitespace is not a reliable delimiter of meaning, as evidenced by multi-word expressions (e.g., ""by the way""), crosslingual variation in the number of words needed to express a concept (e.g., ""spacesuit helmet"" in German is ""raumanzughelm""), and languages that do not use whitespace at all (e.g., Chinese). To explore the potential of tokenization beyond subwords, we introduce a ""superword"" tokenizer, SuperBPE, which incorporates a simple pretokenization curriculum into the byte-pair encoding (BPE) algorithm to first learn subwords, then superwords that bridge whitespace. This brings dramatic improvements in encoding efficiency: when fixing the vocabulary size to 200k, SuperBPE encodes a fixed piece of text with up to 33% fewer tokens than BPE on average. In experiments, we pretrain 8B transformer LMs from scratch while fixing the model size, vocabulary size, and train compute, varying *only* the algorithm for learning the vocabulary. Our model trained with SuperBPE achieves an average +4.0% absolute improvement over the BPE baseline across 30 downstream tasks (including +8.2% on MMLU), while simultaneously requiring 27% less compute at inference time. In analysis, we find that SuperBPE results in segmentations of text that are more uniform in per-token difficulty. Qualitatively, this may be because SuperBPE tokens often capture common multi-word expressions that function semantically as a single unit. SuperBPE is a straightforward, local modification to tokenization that improves both encoding efficiency and downstream performance, yielding better language models overall.",http://arxiv.org/abs/2503.13423v1,"assumption, lm, model, language, tokenization",Quantum Machine Learning,2443,2002
Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI,"Ripan Kumar Kundu, Matthew Denton, Genova Mongalo, Prasad Calyam, Khaza Anuarul Hoque","The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",http://arxiv.org/abs/2503.13419v1,"synergy, vr, ai, intelligence, reality","Quantum Cryptography & Security, Machine Learning & AI in Quantum",1194,2000
FLEX: A Framework for Learning Robot-Agnostic Force-based Skills Involving Sustained Contact Object Manipulation,"Shijie Fang, Wenchang Gao, Shivam Goel, Christopher Thierauf, Matthias Scheutz, Jivko Sinapov","Learning to manipulate objects efficiently, particularly those involving sustained contact (e.g., pushing, sliding) and articulated parts (e.g., drawers, doors), presents significant challenges. Traditional methods, such as robot-centric reinforcement learning (RL), imitation learning, and hybrid techniques, require massive training and often struggle to generalize across different objects and robot platforms. We propose a novel framework for learning object-centric manipulation policies in force space, decoupling the robot from the object. By directly applying forces to selected regions of the object, our method simplifies the action space, reduces unnecessary exploration, and decreases simulation overhead. This approach, trained in simulation on a small set of representative objects, captures object dynamics -- such as joint configurations -- allowing policies to generalize effectively to new, unseen objects. Decoupling these policies from robot-specific dynamics enables direct transfer to different robotic platforms (e.g., Kinova, Panda, UR5) without retraining. Our evaluations demonstrate that the method significantly outperforms baselines, achieving over an order of magnitude improvement in training efficiency compared to other state-of-the-art methods. Additionally, operating in force space enhances policy transferability across diverse robot platforms and object types. We further showcase the applicability of our method in a real-world robotic setting. For supplementary materials and videos, please visit: https://tufts-ai-robotics-group.github.io/FLEX/",http://arxiv.org/abs/2503.13418v1,"contact, drawers, pushing, objects, parts",Machine Learning & AI in Quantum,4565,2004
"A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives","Weiqiang Jin, Hongyang Du, Biao Zhao, Xingwu Tian, Bohang Shi, Guang Yang","With the rapid development of artificial intelligence, intelligent decision-making techniques have gradually surpassed human levels in various human-machine competitions, especially in complex multi-agent cooperative task scenarios. Multi-agent cooperative decision-making involves multiple agents working together to complete established tasks and achieve specific objectives. These techniques are widely applicable in real-world scenarios such as autonomous driving, drone navigation, disaster rescue, and simulated military confrontations. This paper begins with a comprehensive survey of the leading simulation environments and platforms used for multi-agent cooperative decision-making. Specifically, we provide an in-depth analysis for these simulation environments from various perspectives, including task formats, reward allocation, and the underlying technologies employed. Subsequently, we provide a comprehensive overview of the mainstream intelligent decision-making approaches, algorithms and models for multi-agent systems (MAS). Theseapproaches can be broadly categorized into five types: rule-based (primarily fuzzy logic), game theory-based, evolutionary algorithms-based, deep multi-agent reinforcement learning (MARL)-based, and large language models(LLMs)reasoning-based. Given the significant advantages of MARL andLLMs-baseddecision-making methods over the traditional rule, game theory, and evolutionary algorithms, this paper focuses on these multi-agent methods utilizing MARL and LLMs-based techniques. We provide an in-depth discussion of these approaches, highlighting their methodology taxonomies, advantages, and drawbacks. Further, several prominent research directions in the future and potential challenges of multi-agent cooperative decision-making are also detailed.",http://arxiv.org/abs/2503.13415v1,"techniques, decision, levels, intelligence, development",Machine Learning & AI in Quantum,3395,2025
Reward Adaptation Via Q-Manipulation,"Kevin Vora, Yu Zhang","In this paper, we propose a new solution to reward adaptation (RA), the problem where the learning agent adapts to a target reward function based on one or multiple existing behaviors learned a priori under the same domain dynamics but different reward functions. Learning the target behavior from scratch is possible but often inefficient given the available source behaviors. Our work represents a new approach to RA via the manipulation of Q-functions. Assuming that the target reward function is a known function of the source reward functions, our approach to RA computes bounds of the Q function. We introduce an iterative process to tighten the bounds, similar to value iteration. This enables action pruning in the target domain before learning even starts. We refer to such a method as Q-Manipulation (Q-M). We formally prove that our pruning strategy does not affect the optimality of the returned policy while empirically show that it improves the sample complexity. Q-M is evaluated in a variety of synthetic and simulation domains to demonstrate its effectiveness, generalizability, and practicality.",http://arxiv.org/abs/2503.13414v1,"ra, solution, adaptation, problem, paper","Quantum Machine Learning, Machine Learning & AI in Quantum",4127,2022
"DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective","Dengyun Peng, Yuhang Zhou, Qiguang Chen, Jinhao Liu, Jingjing Chen, Libo Qin","Large Language Models (LLMs) have achieved remarkable success across diverse tasks, largely driven by well-designed prompts. However, crafting and selecting such prompts often requires considerable human effort, significantly limiting its scalability. To mitigate this, recent studies have explored automated prompt optimization as a promising solution. Despite these efforts, existing methods still face critical challenges in robustness, efficiency, and generalization. To systematically address these challenges, we first conduct an empirical analysis to identify the limitations of current reflection-based prompt optimization paradigm. Building on these insights, we propose 7 innovative approaches inspired by traditional deep learning paradigms for prompt optimization (DLPO), seamlessly integrating these concepts into text-based gradient optimization. Through these advancements, we progressively tackle the aforementioned challenges and validate our methods through extensive experimentation. We hope our study not only provides valuable guidance for future research but also offers a comprehensive understanding of the challenges and potential solutions in prompt optimization. Our code is available at https://github.com/sfasfaffa/DLPO.",http://arxiv.org/abs/2503.13413v1,"models, tasks, llms, success, language",Machine Learning & AI in Quantum,4853,2013
Mixed spin-boson coupling for qubit readout with suppressed residual shot-noise dephasing,"Jinlun Hu, Antonio L. R. Manesco, Andr? Melo, Taryn V. Stefanski, Christian Kraglund Andersen, Valla Fatemi","Direct dipole coupling between a two-level system and a bosonic mode describes the interactions present in a wide range of physical platforms. In this work, we study a coupling that is mixed between two pairs of quadratures of a bosonic mode and a spin. In this setting, we can suppress the dispersive shift while retaining a nonzero Kerr shift, which remarkably results in a cubic relationship between shot noise dephasing and thermal photons in the oscillator. We demonstrate this configuration with a simple toy model, quantify the expected improvements to photon shot-noise dephasing of the spin, and describe an approach to fast qubit readout via the Kerr shift. Further, we show how such a regime is achievable in superconducting circuits because magnetic and electric couplings can be of comparable strength, using two examples: the Cooper pair transistor and the fluxonium molecule.",http://arxiv.org/abs/2503.13411v1,"dipole, mode, level, system, coupling",Quantum Computing & Information,2914,2006
Realizing a Symmetry Protected Topological Phase in a Superconducting Circuit,"Parameshwar R. Pasnoori, Patrick Azaria, Ari Mizel","We propose a superconducting quantum circuit whose low-energy degrees of freedom are described by the sine-Gordon (SG) quantum field theory. For suitably chosen parameters,   the circuit hosts a symmetry protected topological (SPT) phase protected by a discrete $\mathbb{Z}_2$ symmetry. The ground state of the system is twofold degenerate and exhibits local spontaneous symmetry breaking of the $\mathbb{Z}_2$ symmetry close to the edges of the circuit, leading to spontaneous localized edge supercurrents. The ground states host Majorana zero modes (MZM) at the edges of the circuit. On top of each of the two ground states, the system exhibits localized bound states at both edges, which are topologically protected against small disorder in the bulk. The spectrum of these boundary excitations should be observable in a circuit-QED experiment with feasible parameter choices.",http://arxiv.org/abs/2503.13406v1,"degrees, freedom, circuit, energy, quantum",Quantum Computing & Information,484,2008
Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning,"Cheoljoon Jeong, Xubo Yue, Seokhyun Chung","Many failure mechanisms of machinery are closely related to the behavior of condition monitoring (CM) signals. To achieve a cost-effective preventive maintenance strategy, accurate remaining useful life (RUL) prediction based on the signals is of paramount importance. However, the CM signals are often recorded at different factories and production lines, with limited amounts of data. Unfortunately, these datasets have rarely been shared between the sites due to data confidentiality and ownership issues, a lack of computing and storage power, and high communication costs associated with data transfer between sites and a data center. Another challenge in real applications is that the CM signals are often not explicitly specified \textit{a priori}, meaning that existing methods, which often usually a parametric form, may not be applicable. To address these challenges, we propose a new prognostic framework for RUL prediction using the joint modeling of nonlinear degradation signals and time-to-failure data within a federated learning scheme. The proposed method constructs a nonparametric degradation model using a federated multi-output Gaussian process and then employs a federated survival model to predict failure times and probabilities for in-service machinery. The superiority of the proposed method over other alternatives is demonstrated through comprehensive simulation studies and a case study using turbofan engine degradation signal data that include run-to-failure events.",http://arxiv.org/abs/2503.13404v1,"machinery, condition, mechanisms, behavior, failure","Machine Learning & AI in Quantum, Quantum Machine Learning",1092,2014
Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis,"Alexander Ku, Declan Campbell, Xuechunzi Bai, Jiayi Geng, Ryan Liu, Raja Marjieh, R. Thomas McCoy, Andrew Nam, Ilia Sucholutsky, Veniamin Veselovsky, Liyi Zhang, Jian-Qiao Zhu, Thomas L. Griffiths","Modern artificial intelligence systems, such as large language models, are increasingly powerful but also increasingly hard to understand. Recognizing this problem as analogous to the historical difficulties in understanding the human mind, we argue that methods developed in cognitive science can be useful for understanding large language models. We propose a framework for applying these methods based on Marr's three levels of analysis. By revisiting established cognitive science techniques relevant to each level and illustrating their potential to yield insights into the behavior and internal organization of large language models, we aim to provide a toolkit for making sense of these new kinds of minds.",http://arxiv.org/abs/2503.13401v1,"systems, models, problem, intelligence, language",Machine Learning & AI in Quantum,2568,2014
MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research,"James Burgess, Jeffrey J Nirschl, Laura Bravo-S?nchez, Alejandro Lozano, Sanket Rajan Gupte, Jesus G. Galaz-Montoya, Yuhui Zhang, Yuchang Su, Disha Bhowmik, Zachary Coman, Sarina M. Hasan, Alexandra Johannesson, William D. Leineweber, Malvika G Nair, Ridhi Yarlagadda, Connor Zuraski, Wah Chiu, Sarah Cohen, Jan N. Hansen, Manuel D Leonetti, Chad Liu, Emma Lundberg, Serena Yeung-Levy","Scientific research demands sophisticated reasoning over multimodal data, a challenge especially prevalent in biology. Despite recent advances in multimodal large language models (MLLMs) for AI-assisted research, existing multimodal reasoning benchmarks only target up to college-level difficulty, while research-level benchmarks emphasize lower-level perception, falling short of the complex multimodal reasoning needed for scientific discovery. To bridge this gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark designed to assess three reasoning capabilities vital in research workflows: expert image understanding, hypothesis generation, and experiment proposal. MicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology experts across diverse microscopy modalities, ensuring VQA samples represent real scientific practice. In constructing the benchmark, we find that standard MCQ generation methods induce language shortcuts, motivating a new two-stage pipeline: an optimized LLM prompt structures question-answer pairs into MCQs; then, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking on state-of-the-art MLLMs reveal a peak performance of 53\%; models with smaller LLMs only slightly underperform top models, suggesting that language-based reasoning is less challenging than multimodal reasoning; and tuning with scientific articles enhances performance. Expert analysis of chain-of-thought responses shows that perception errors are the most frequent, followed by knowledge errors and then overgeneralization errors. These insights highlight the challenges in multimodal scientific reasoning, showing MicroVQA is a valuable resource advancing AI-driven biomedical research. MicroVQA is available at https://huggingface.co/datasets/jmhb/microvqa, and project page at https://jmhb0.github.io/microvqa.",http://arxiv.org/abs/2503.13399v1,"data, biology, challenge, reasoning, research","Machine Learning & AI in Quantum, Quantum Machine Learning",2057,2025
Investigating the effect of CPT in lateral spreading prediction using Explainable AI,"Cheng-Hsi Hsiao, Ellen Rathje, Krishna Kumar","This study proposes an autoencoder approach to extract latent features from cone penetration test profiles to evaluate the potential of incorporating CPT data in an AI model. We employ autoencoders to compress 200 CPT profiles of soil behavior type index (Ic) and normalized cone resistance (qc1Ncs) into ten latent features while preserving critical information. We then utilize the extracted latent features with site parameters to train XGBoost models for predicting lateral spreading occurrences in the 2011 Christchurch earthquake. Models using the latent CPT features outperformed models with conventional CPT metrics or no CPT data, achieving over 83% accuracy. Explainable AI revealed the most crucial latent feature corresponding to soil behavior between 1-3 meter depths, highlighting this depth range's criticality for liquefaction evaluation. The autoencoder approach provides an automated technique for condensing CPT profiles into informative latent features for machine-learning liquefaction models.",http://arxiv.org/abs/2503.13389v1,"features, study, latent, approach, autoencoder",Quantum Machine Learning,2757,2009
A mathematical model for a universal digital quantum computer with an application to the Grover-Rudolph algorithm,"Antonio Falc?, Daniela Falc?--Pomares, Hermann G. Matthies","In this work, we develop a novel mathematical framework for universal digital quantum computation using algebraic probability theory. We rigorously define quantum circuits as finite sequences of elementary quantum gates and establish their role in implementing unitary transformations. A key result demonstrates that every unitary matrix in \(\mathrm{U}(N)\) can be expressed as a product of elementary quantum gates, leading to the concept of a universal dictionary for quantum computation. We apply this framework to the construction of quantum circuits that encode probability distributions, focusing on the Grover-Rudolph algorithm. By leveraging controlled quantum gates and rotation matrices, we design a quantum circuit that approximates a given probability density function. Numerical simulations, conducted using Qiskit, confirm the theoretical predictions and validate the effectiveness of our approach. These results provide a rigorous foundation for quantum circuit synthesis within an algebraic probability framework and offer new insights into the encoding of probability distributions in quantum algorithms. Potential applications include quantum machine learning, circuit optimization, and experimental implementations on real quantum hardware.",http://arxiv.org/abs/2503.13388v1,"computation, probability, work, quantum, framework",Quantum Computing & Information,985,2012
Scale Efficient Training for Large Datasets,"Qing Zhou, Junyu Gao, Qi Wang","The rapid growth of dataset scales has been a key driver in advancing deep learning research. However, as dataset scale increases, the training process becomes increasingly inefficient due to the presence of low-value samples, including excessive redundant samples, overly challenging samples, and inefficient easy samples that contribute little to model improvement.To address this challenge, we propose Scale Efficient Training (SeTa) for large datasets, a dynamic sample pruning approach that losslessly reduces training time. To remove low-value samples, SeTa first performs random pruning to eliminate redundant samples, then clusters the remaining samples according to their learning difficulty measured by loss. Building upon this clustering, a sliding window strategy is employed to progressively remove both overly challenging and inefficient easy clusters following an easy-to-hard curriculum.We conduct extensive experiments on large-scale synthetic datasets, including ToCa, SS1M, and ST+MJ, each containing over 3 million samples.SeTa reduces training costs by up to 50\% while maintaining or improving performance, with minimal degradation even at 70\% cost reduction. Furthermore, experiments on various scale real datasets across various backbones (CNNs, Transformers, and Mambas) and diverse tasks (instruction tuning, multi-view stereo, geo-localization, composed image retrieval, referring image segmentation) demonstrate the powerful effectiveness and universality of our approach. Code is available at https://github.com/mrazhou/SeTa.",http://arxiv.org/abs/2503.13385v1,"learning, research, driver, growth, scales","Machine Learning & AI in Quantum, Quantum Machine Learning",1816,2018
"Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning","Mengyao Lyu, Yan Li, Huasong Zhong, Wenhao Yang, Hui Chen, Jungong Han, Guiguang Ding, Zhenheng Yang","The hypothesis that pretrained large language models (LLMs) necessitate only minimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has been substantiated by recent advancements in data curation and selection research. However, their stability and generalizability are compromised due to the vulnerability to experimental setups and validation protocols, falling short of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al., 2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer token volume and heightened heterogeneity of data sources, amplify both the significance and complexity of data selection.   To harvest multi-modal instructional data in a robust and efficient manner, we re-define the granularity of the quality metric by decomposing it into 14 vision-language-related capabilities, and introduce multi-modal rich scorers to evaluate the capabilities of each data candidate. To promote diversity, in light of the inherent objective of the alignment stage, we take interaction style as diversity indicator and use a multi-modal rich styler to identify data instruction patterns. In doing so, our multi-modal rich scorers and styler (mmSSR) guarantee that high-scoring information is conveyed to users in diversified forms. Free from embedding-based clustering or greedy sampling, mmSSR efficiently scales to millions of data with varying budget constraints, supports customization for general or specific capability acquisition, and facilitates training-free generalization to new domains for curation. Across 10+ experimental settings, validated by 14 multi-modal benchmarks, we demonstrate consistent improvements over random sampling, baseline strategies and state-of-the-art selection methods, achieving 99.1% of full performance with only 30% of the 2.6M data.",http://arxiv.org/abs/2503.13383v1,"supervision, models, llms, hypothesis, language","Machine Learning & AI in Quantum, Quantum Machine Learning",199,2006
Error bounds for composite quantum hypothesis testing and a new characterization of the weighted Kubo-Ando geometric means,"P?ter E. Frenkel, Mil?n Mosonyi, P?ter Vrana, Mih?ly Weiner","The optimal error exponents of binary composite i.i.d. state discrimination are trivially bounded by the worst-case pairwise exponents of discriminating individual elements of the sets representing the two hypotheses, and in the finite-dimensional classical case, these bounds in fact give exact single-copy expressions for the error exponents. In contrast, in the non-commutative case, the optimal exponents are only known to be expressible in terms of regularized divergences, resulting in formulas that, while conceptually relevant, practically not very useful. In this paper, we develop further an approach initiated in [Mosonyi, Szil\'agyi, Weiner, IEEE Trans. Inf. Th. 68(2):1032--1067, 2022] to give improved single-copy bounds on the error exponents by comparing not only individual states from the two hypotheses, but also various unnormalized positive semi-definite operators associated to them. Here, we show a number of equivalent characterizations of such operators giving valid bounds, and show that in the commutative case, considering weighted geometric means of the states, and in the case of two states per hypothesis, considering weighted Kubo-Ando geometric means, are optimal for this approach. As a result, we give a new characterization of the weighted Kubo-Ando geometric means as the only $2$-variable operator geometric means that are block additive, tensor multiplicative, and satisfy the arithmetic-geometric mean inequality. We also extend our results to composite quantum channel discrimination, and show an analogous optimality property of the weighted Kubo-Ando geometric means of two quantum channels, a notion that seems to be new. We extend this concept to defining the notion of superoperator perspective function and establish some of its basic properties, which may be of independent interest.",http://arxiv.org/abs/2503.13379v1,"exponents, error, discrimination, i.i.d, state","Quantum Computing & Information, Mathematical & Theoretical Quantum Physics",2744,2016
TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM,"Ye Wang, Boshen Xu, Zihao Yue, Zihan Xiao, Ziheng Wang, Liang Zhang, Dingyi Yang, Wenxuan Wang, Qin Jin","We introduce TimeZero, a reasoning-guided LVLM designed for the temporal video grounding (TVG) task. This task requires precisely localizing relevant video segments within long videos based on a given language query. TimeZero tackles this challenge by extending the inference process, enabling the model to reason about video-language relationships solely through reinforcement learning. To evaluate the effectiveness of TimeZero, we conduct experiments on two benchmarks, where TimeZero achieves state-of-the-art performance on Charades-STA. Code is available at https://github.com/www-Ye/TimeZero.",http://arxiv.org/abs/2503.13377v1,"lvlm, grounding, reasoning, timezero, video",Machine Learning & AI in Quantum,3015,2019
Approach to equilibrium in Markovian open quantum systems,"Donghao Ouyang, Israel Michael Sigal","In this paper, we study the evolution of Markovian open quantum systems, whose dynamics are governed by the von Neumann-Lindblad equations. Our goal is to prove the return-to-equilibrium property for systems of infinite degrees of freedom under quantum detailed balance condition.",http://arxiv.org/abs/2503.13376v1,"evolution, systems, markovian, quantum, paper","Quantum Computing & Information, Mathematical & Theoretical Quantum Physics",4668,2003
Revival and instabilities of entanglement in monitoring maps with indefinite causal order,"Shahana Aziz, Andr? H. A. Malavazi, Pedro R. Dieguez","In this proceeding, we revisit the discussion presented in Ref. [Commun Phys 7, 373 (2024)], which examines the behavior of a quantum switch involving two arbitrary quantum operations when the control is exposed to environmental effects. Our study extends this analysis by focusing on the evolution of entanglement in the target system within the quantum switch framework, taking into account the influence of environmental conditions and control post-selection. We find that entanglement evolution is highly sensitive to these factors. While entanglement sudden death occurs under definite causal order, indefinite causal order can reverse this loss. We observe entanglement revival in high-temperature regimes and a sudden reappearance of entanglement under weak monitoring conditions at low temperatures. These findings provide insights into the resilience of the quantum switch in the presence of environmental disturbances and highlight its potential for applications where preserving entanglement is essential.",http://arxiv.org/abs/2503.13373v1,"proceeding, commun, discussion, ref, phys",Quantum Computing & Information,1909,2004
SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked Temporal Visual Prior for Improved Synchronization,"Xulin Fan, Heting Gao, Ziyi Chen, Peng Chang, Mei Han, Mark Hasegawa-Johnson","Talking head synthesis, also known as speech-to-lip synthesis, reconstructs the facial motions that align with the given audio tracks. The synthesized videos are evaluated on mainly two aspects, lip-speech synchronization and image fidelity. Recent studies demonstrate that GAN-based and diffusion-based models achieve state-of-the-art (SOTA) performance on this task, with diffusion-based models achieving superior image fidelity but experiencing lower synchronization compared to their GAN-based counterparts. To this end, we propose SyncDiff, a simple yet effective approach to improve diffusion-based models using a temporal pose frame with information bottleneck and facial-informative audio features extracted from AVHuBERT, as conditioning input into the diffusion process. We evaluate SyncDiff on two canonical talking head datasets, LRS2 and LRS3 for direct comparison with other SOTA models. Experiments on LRS2/LRS3 datasets show that SyncDiff achieves a synchronization score 27.7%/62.3% relatively higher than previous diffusion-based methods, while preserving their high-fidelity characteristics.",http://arxiv.org/abs/2503.13371v1,"synthesis, speech, head, lip",Quantum Machine Learning,1277,2022
Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions,"Wan Ju Kang, Eunki Kim, Na Min An, Sangryul Kim, Haemin Choi, Ki Hoon Kwak, James Thorne","Often, the needs and visual abilities differ between the annotator group and the end user group. Generating detailed diagram descriptions for blind and low-vision (BLV) users is one such challenging domain. Sighted annotators could describe visuals with ease, but existing studies have shown that direct generations by them are costly, bias-prone, and somewhat lacking by BLV standards. In this study, we ask sighted individuals to assess -- rather than produce -- diagram descriptions generated by vision-language models (VLM) that have been guided with latent supervision via a multi-pass inference. The sighted assessments prove effective and useful to professional educators who are themselves BLV and teach visually impaired learners. We release Sightation, a collection of diagram description datasets spanning 5k diagrams and 137k samples for completion, preference, retrieval, question answering, and reasoning training purposes and demonstrate their fine-tuning potential in various downstream tasks.",http://arxiv.org/abs/2503.13369v1,"needs, annotator, abilities, end, group",Machine Learning & AI in Quantum,1538,2006
Exploring new variational quantum circuit ansatzes for solving $SU(2)$ matrix models,H. L. Dao,"In this work, we explored and experimented with new forms of parameterized quantum circuits to be used as variational ansatzes for solving the bosonic and supersymmetric $SU(2)$ matrix models at different couplings using the Variational Quantum Eigensolver (VQE) algorithm. Working with IBM Qiskit quantum computing platform, we show that two types of quantum circuits named \texttt{TwoLocal} and \texttt{EvolvedOperatorAnsatz} can outperform the popular \texttt{EfficientSU2} circuits which have been routinely used in the recent quantum physics literature to run VQE. With their more customizable constructions that allow for more flexibility beyond choosing the types of parameterized rotation gates, both types of new circuit ansatzes used in this work have led to performances that are either better than or at least comparable to \texttt{EfficientSU2} in the setting of $SU(2)$ matrix models. In particular, in the strong coupling regimes of the bosonic model, both \texttt{TwoLocal} and \texttt{EvolvedOperatorAnsatz} circuits provided a better approximation to the exact ground states, while in the supersymmetric model, shallow \texttt{EvolvedOperatorAnsatz} circuits with small a number of parameters, attained a comparable albeit not as good performance as the much deeper \texttt{EfficientSU2} circuits with around 8 to 9 times more parameters. The results of this work demonstrate conclusively the potential of \texttt{TwoLocal} and \texttt{EvolvedOperatorAnsatz} quantum circuits as efficient new types of variational ansatzes that should be considered more frequently in future VQE studies of quantum physics systems.",http://arxiv.org/abs/2503.13368v1,"ansatzes, circuits, forms, work, quantum",Quantum Computing & Information,3212,2012
Follow-the-Regularized-Leader with Adversarial Constraints,"Ricardo N. Ferreira, Cl?udia Soares","Constrained Online Convex Optimization (COCO) can be seen as a generalization of the standard Online Convex Optimization (OCO) framework. At each round, a cost function and constraint function are revealed after a learner chooses an action. The goal is to minimize both the regret and cumulative constraint violation (CCV) against an adaptive adversary. We show for the first time that is possible to obtain the optimal $O(\sqrt{T})$ bound on both regret and CCV, improving the best known bounds of $O \left( \sqrt{T} \right)$ and $\~{O} \left( \sqrt{T} \right)$ for the regret and CCV, respectively.",http://arxiv.org/abs/2503.13366v1,"optimization, coco, constrained, online, convex",Quantum Machine Learning,3566,2014
Demonstration of a Tunable Non-Hermitian Nonlinear Microwave Dimer,"Juan S. Salcedo-Gallo, Michiel Burgelman, Vincent P. Flynn, Alexander S. Carney, Majd Hamdan, Tunmay Gerg, Daniel C. Smallwood, Lorenza Viola, Mattias Fitzpatrick","Achieving and controlling non-reciprocity in engineered photonic structures is of fundamental interest in science and engineering. Here, we introduce a tunable, non-Hermitian, nonlinear microwave dimer designed to precisely implement phase-non-reciprocal hopping dynamics between two spatially separated cavities at room temperature. Our system incorporates simple components such as three-dimensional microwave cavities, unidirectional amplifiers, digital attenuators, and a digital phase shifter. By dividing the energy transfer into forward and backward paths, our platform enables precise control over the amplitude and phase of the propagating signals in each direction. Through a combination of theoretical and numerical analysis, we model the dynamics of the system under different operating conditions, including a parameter regime where the gain not only compensates for but significantly exceeds the inherent loss. Our model quantitatively reproduces the observed weak-drive transmission spectra, the amplitude and frequency of self-sustained limit cycles, and the synchronization effect between the limit cycle and an external microwave tone. Our results may have implications in areas ranging from sensing and synthetic photonic materials to neuromorphic computing and quantum networks, while providing new insight into the interplay between non-Hermitian and nonlinear dynamics.",http://arxiv.org/abs/2503.13364v1,"science, interest, structures, engineering, reciprocity",Quantum Computing & Information,3900,2010
Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning,"Hai-Long Sun, Zhun Sun, Houwen Peng, Han-Jia Ye","Recent advancements in Large Language Models (LLMs) have demonstrated enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting to advanced, product-oriented solutions like OpenAI o1. During our re-implementation of this model, we noticed that in multimodal tasks requiring visual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to maintain focus on the visual information, in other words, MLLMs suffer from a gradual decline in attention to visual information as reasoning progresses, causing text-over-relied outputs. To investigate this, we ablate image inputs during long-chain reasoning. Concretely, we truncate the reasoning process midway, then re-complete the reasoning process with the input image removed. We observe only a ~2% accuracy drop on MathVista's test-hard subset, revealing the model's textual outputs dominate the following reasoning process. Motivated by this, we propose Take-along Visual Conditioning (TVC), a strategy that shifts image input to critical reasoning stages and compresses redundant visual tokens via dynamic pruning. This methodology helps the model retain attention to the visual components throughout the reasoning. Our approach achieves state-of-the-art performance on average across five mathematical reasoning benchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in enhancing multimodal reasoning systems.",http://arxiv.org/abs/2503.13360v1,"advancements, models, llms, language, large","Machine Learning & AI in Quantum, Quantum Machine Learning",656,2003
Agents Play Thousands of 3D Video Games,"Zhongwen Xu, Xianliang Wang, Siyi Li, Tao Yu, Liang Wang, Qiang Fu, Wei Yang","We present PORTAL, a novel framework for developing artificial intelligence agents capable of playing thousands of 3D video games through language-guided policy generation. By transforming decision-making problems into language modeling tasks, our approach leverages large language models (LLMs) to generate behavior trees represented in domain-specific language (DSL). This method eliminates the computational burden associated with traditional reinforcement learning approaches while preserving strategic depth and rapid adaptability. Our framework introduces a hybrid policy structure that combines rule-based nodes with neural network components, enabling both high-level strategic reasoning and precise low-level control. A dual-feedback mechanism incorporating quantitative game metrics and vision-language model analysis facilitates iterative policy improvement at both tactical and strategic levels. The resulting policies are instantaneously deployable, human-interpretable, and capable of generalizing across diverse gaming environments. Experimental results demonstrate PORTAL's effectiveness across thousands of first-person shooter (FPS) games, showcasing significant improvements in development efficiency, policy generalization, and behavior diversity compared to traditional approaches. PORTAL represents a significant advancement in game AI development, offering a practical solution for creating sophisticated agents that can operate across thousands of commercial video games with minimal development overhead. Experiment results on the 3D video games are best viewed on https://zhongwen.one/projects/portal .",http://arxiv.org/abs/2503.13356v1,"agents, intelligence, thousands, framework, portal",Quantum Machine Learning,2898,2012
Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations,"Ewan R. S. Wallace, Nathan C. Frey, Joshua A. Rackers","Ligand strain energy, the energy difference between the bound and unbound conformations of a ligand, is an important component of structure-based small molecule drug design. A large majority of observed ligands in protein-small molecule co-crystal structures bind in low-strain conformations, making strain energy a useful filter for structure-based drug design. In this work we present a tool for calculating ligand strain with a high accuracy. StrainRelief uses a MACE Neural Network Potential (NNP), trained on a large database of Density Functional Theory (DFT) calculations to estimate ligand strain of neutral molecules with quantum accuracy. We show that this tool estimates strain energy differences relative to DFT to within 1.4 kcal/mol, more accurately than alternative NNPs. These results highlight the utility of NNPs in drug discovery, and provide a useful tool for drug discovery teams.",http://arxiv.org/abs/2503.13352v1,"difference, ligand, energy, conformations",Quantum Machine Learning,2445,2006
"Scalable Runtime Architecture for Data-driven, Hybrid HPC and ML Workflow Applications","Andre Merzky, Mikhail Titov, Matteo Turilli, Ozgur Kilic, Tianle Wang, Shantenu Jha","Hybrid workflows combining traditional HPC and novel ML methodologies are transforming scientific computing. This paper presents the architecture and implementation of a scalable runtime system that extends RADICAL-Pilot with service-based execution to support AI-out-HPC workflows. Our runtime system enables distributed ML capabilities, efficient resource management, and seamless HPC/ML coupling across local and remote platforms. Preliminary experimental results show that our approach manages concurrent execution of ML models across local and remote HPC/cloud resources with minimal architectural overheads. This lays the foundation for prototyping three representative data-driven workflow applications and executing them at scale on leadership-class HPC platforms.",http://arxiv.org/abs/2503.13343v1,"hpc, hybrid, methodologies, computing, ml",Machine Learning & AI in Quantum,610,2018
Valid Text-to-SQL Generation with Unification-based DeepStochLog,"Ying Jiao, Luc De Raedt, Giuseppe Marra","Large language models have been used to translate natural language questions to SQL queries. Without hard constraints on syntax and database schema, they occasionally produce invalid queries that are not executable. These failures limit the usage of these systems in real-life scenarios. We propose a neurosymbolic framework that imposes SQL syntax and schema constraints with unification-based definite clause grammars and thus guarantees the generation of valid queries. Our framework also builds a bi-directional interface to language models to leverage their natural language understanding abilities. The evaluation results on a subset of SQL grammars show that all our output queries are valid. This work is the first step towards extending language models with unification-based grammars. We demonstrate this extension enhances the validity, execution accuracy, and ground truth alignment of the underlying language model by a large margin. Our code is available at https://github.com/ML-KULeuven/deepstochlog-lm.",http://arxiv.org/abs/2503.13342v1,"models, language, sql, questions",Machine Learning & AI in Quantum,2373,2021
Reliable and Efficient Amortized Model-based Evaluation,"Sang Truong, Yuheng Tu, Percy Liang, Bo Li, Sanmi Koyejo","Comprehensive evaluations of language models (LM) during both development and deployment phases are necessary because these models possess numerous capabilities (e.g., mathematical reasoning, legal support, or medical diagnostic) as well as safety risks (e.g., racial bias, toxicity, or misinformation). The average score across a wide range of benchmarks provides a signal that helps guide the use of these LMs in practice. Currently, holistic evaluations are costly due to the large volume of benchmark questions, making frequent evaluations impractical. A popular attempt to lower the cost is to compute the average score on a subset of the benchmark. This approach, unfortunately, often renders an unreliable measure of LM performance because the average score is often confounded with the difficulty of the questions in the benchmark subset. Item response theory (IRT) was designed to address this challenge, providing a reliable measurement by careful controlling for question difficulty. Unfortunately, question difficulty is expensive to estimate. Facing this challenge, we train a model that predicts question difficulty from its content, enabling a reliable measurement at a fraction of the cost. In addition, we leverage this difficulty predictor to further improve the evaluation efficiency through training a question generator given a difficulty level. This question generator is essential in adaptive testing, where, instead of using a random subset of the benchmark questions, informative questions are adaptively chosen based on the current estimation of LLM performance. Experiments on 22 common natural language benchmarks and 172 LMs show that this approach is more reliable and efficient compared to current common practice.",http://arxiv.org/abs/2503.13335v1,"lm, models, language, evaluations, development","Machine Learning & AI in Quantum, Quantum Machine Learning",2071,2001
LEAVS: An LLM-based Labeler for Abdominal CT Supervision,"Ricardo Bigolin Lanfredi, Yan Zhuang, Mark Finkelstein, Praveen Thoppey Srinivasan Balamuralikrishna, Luke Krembs, Brandon Khoury, Arthi Reddy, Pritam Mukherjee, Neil M. Rofsky, Ronald M. Summers","Extracting structured labels from radiology reports has been employed to create vision models to simultaneously detect several types of abnormalities. However, existing works focus mainly on the chest region. Few works have been investigated on abdominal radiology reports due to more complex anatomy and a wider range of pathologies in the abdomen. We propose LEAVS (Large language model Extractor for Abdominal Vision Supervision). This labeler can annotate the certainty of presence and the urgency of seven types of abnormalities for nine abdominal organs on CT radiology reports. To ensure broad coverage, we chose abnormalities that encompass most of the finding types from CT reports. Our approach employs a specialized chain-of-thought prompting strategy for a locally-run LLM using sentence extraction and multiple-choice questions in a tree-based decision system. We demonstrate that the LLM can extract several abnormality types across abdominal organs with an average F1 score of 0.89, significantly outperforming competing labelers and humans. Additionally, we show that extraction of urgency labels achieved performance comparable to human annotations. Finally, we demonstrate that the abnormality labels contain valuable information for training a single vision model that classifies several organs as normal or abnormal. We release our code and structured annotations for a public CT dataset containing over 1,000 CT volumes.",http://arxiv.org/abs/2503.13330v1,"vision, reports, models, radiology, labels",Machine Learning & AI in Quantum,251,2009
"PERC: a suite of software tools for the curation of cryoEM data with application to simulation, modelling and machine learning","Beatriz Costa-Gomes, Joel Greer, Nikolai Juraschko, James Parkhurst, Jola Mirecka, Marjan Famili, Camila Rangel-Smith, Oliver Strickson, Alan Lowe, Mark Basham, Tom Burnley","Ease of access to data, tools and models expedites scientific research. In structural biology there are now numerous open repositories of experimental and simulated datasets. Being able to easily access and utilise these is crucial for allowing researchers to make optimal use of their research effort. The tools presented here are useful for collating existing public cryoEM datasets and/or creating new synthetic cryoEM datasets to aid the development of novel data processing and interpretation algorithms. In recent years, structural biology has seen the development of a multitude of machine-learning based algorithms for aiding numerous steps in the processing and reconstruction of experimental datasets and the use of these approaches has become widespread. Developing such techniques in structural biology requires access to large datasets which can be cumbersome to curate and unwieldy to make use of. In this paper we present a suite of Python software packages which we collectively refer to as PERC (profet, EMPIARreader and CAKED). These are designed to reduce the burden which data curation places upon structural biology research. The protein structure fetcher (profet) package allows users to conveniently download and cleave sequences or structures from the Protein Data Bank or Alphafold databases. EMPIARreader allows lazy loading of Electron Microscopy Public Image Archive datasets in a machine-learning compatible structure. The Class Aggregator for Key Electron-microscopy Data (CAKED) package is designed to seamlessly facilitate the training of machine learning models on electron microscopy data, including electron-cryo-microscopy-specific data augmentation and labelling. These packages may be utilised independently or as building blocks in workflows. All are available in open source repositories and designed to be easily extensible to facilitate more advanced workflows if required.",http://arxiv.org/abs/2503.13329v1,"data, tools, models, ease, access",Quantum Machine Learning,2051,2012
SMPR: A structure-enhanced multimodal drug-disease prediction model for drug repositioning and cold start,"Xin Dong, Rui Miao, Suyan Zhang, Shuaibing Jia, Leifeng Zhang, Yong Liang, Jianhua Zhang, Yi Zhun Zhu","Repositioning drug-disease relationships has always been a hot field of research. However, actual cases of biologically validated drug relocation remain very limited, and existing models have not yet fully utilized the structural information of the drug. Furthermore, most repositioning models are only used to complete the relationship matrix, and their practicality is poor when dealing with drug cold start problems. This paper proposes a structure-enhanced multimodal relationship prediction model (SMRP). SMPR is based on the SMILE structure of the drug, using the Mol2VEC method to generate drug embedded representations, and learn disease embedded representations through heterogeneous network graph neural networks. Ultimately, a drug-disease relationship matrix is constructed. In addition, to reduce the difficulty of users' use, SMPR also provides a cold start interface based on structural similarity based on reposition results to simply and quickly predict drug-related diseases. The repositioning ability and cold start capability of the model are verified from multiple perspectives. While the AUC and ACUPR scores of repositioning reach 99% and 61% respectively, the AUC of cold start achieve 80%. In particular, the cold start Recall indicator can reach more than 70%, which means that SMPR is more sensitive to positive samples. Finally, case analysis is used to verify the practical value of the model and visual analysis directly demonstrates the improvement of the structure to the model. For quick use, we also provide local deployment of the model and package it into an executable program.",http://arxiv.org/abs/2503.13322v1,"research, field, relationships, drug, disease",Quantum Machine Learning,2834,2024
Study of Magnetic Field Resilient High Impedance High-Kinetic Inductance Superconducting Resonators,"Camille Roy, Simone Frasca, Pasquale Scarlino","Superconducting resonators with high-kinetic inductance play a central role in hybrid quantum circuits, enabling strong coupling with quantum systems with small electric dipole moment and improved parametric amplification. However, optimizing these resonators simultaneously for high internal quality factors ($Q_i$) and resilience to strong magnetic fields remains challenging. In this study, we systematically compare superconducting resonators fabricated from niobium nitride (NbN) and granular aluminum (grAl) thin films, each having similar kinetic inductance values ($L_k \sim 100$ pH/sq). At zero magnetic field, resonators made from grAl exhibit higher $Q_i$ compared to their NbN counterparts. However, under applied magnetic fields, NbN resonators demonstrate significantly better resilience. Moreover, NbN resonators exhibit an unexpected increase in $Q_i$ at intermediate in-plane magnetic fields ($B_{\parallel} \sim 1$ T), which we attribute to an enhanced frequency detuning that reduce coupling to two-level system defects. In contrast, grAl resonators show a distinct critical field above which $Q_i$ rapidly decreases, strongly depending on resonator cross-section respect to the applied field direction. Characterization of the nonlinear properties at zero magnetic field reveals that the self-Kerr coefficient in grAl resonators is more than an order of magnitude higher than in NbN resonators, making grAl particularly attractive for applications requiring pronounced nonlinear interactions. Our findings illustrate a clear trade-off between the two materials: NbN offers superior magnetic-field resilience beneficial for hybrid circuit quantum electrodynamics applications, while grAl is more advantageous in low-field regimes demanding high impedance and strong nonlinearity.",http://arxiv.org/abs/2503.13321v1,"kinetic, resonators, quantum, inductance, role",Quantum Computing & Information,2622,2020
Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression,"Enrico Foglia, Benjamin Bobbia, Nikita Durasov, Michael Bauerheim, Pascal Fua, Stephane Moreau, Thierry Jardin","Quantifying model uncertainty is critical for understanding prediction reliability, yet distinguishing between aleatoric and epistemic uncertainty remains challenging. We extend recent work from classification to regression to provide a novel frequentist approach to epistemic and aleatoric uncertainty estimation. We train models to generate conditional predictions by feeding their initial output back as an additional input. This method allows for a rigorous measurement of model uncertainty by observing how prediction responses change when conditioned on the model's previous answer. We provide a complete theoretical framework to analyze epistemic uncertainty in regression in a frequentist way, and explain how it can be exploited in practice to gauge a model's uncertainty, with minimal changes to the original architecture.",http://arxiv.org/abs/2503.13317v1,"uncertainty, prediction, reliability, model, quantifying",Quantum Machine Learning,1373,2005
RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling,"Marcello Iotti, Paolo Davini, Jost von Hardenberg, Giuseppe Zappa","To this day, accurately simulating local-scale precipitation and reliably reproducing its distribution remains a challenging task. The limited horizontal resolution of Global Climate Models is among the primary factors undermining their skill in this context. The physical mechanisms driving the onset and development of precipitation, especially in extreme events, operate at spatio-temporal scales smaller than those numerically resolved, thus struggling to be captured accurately. In order to circumvent this limitation, several downscaling approaches have been developed over the last decades to address the discrepancy between the spatial resolution of models output and the resolution required by local-scale applications. In this paper, we introduce RainScaleGAN, a conditional deep convolutional Generative Adversarial Network (GAN) for precipitation downscaling. GANs have been effectively used in image super-resolution, an approach highly relevant for downscaling tasks. RainScaleGAN's capabilities are tested in a perfect-model setup, where the spatial resolution of a precipitation dataset is artificially degraded from 0.25$^{\circ}\times$0.25$^{\circ}$ to 2$^{\circ}\times$2$^\circ$, and RainScaleGAN is used to restore it. The developed model outperforms one of the leading precipitation downscaling method found in the literature. RainScaleGAN not only generates a synthetic dataset featuring plausible high-resolution spatial patterns and intensities, but also produces a precipitation distribution with statistics closely mirroring those of the ground-truth dataset. Given that RainScaleGAN's approach is agnostic with respect to the underlying physics, the method has the potential to be applied to other physical variables such as surface winds or temperature.",http://arxiv.org/abs/2503.13316v1,"scale, distribution, precipitation, task, day","Machine Learning & AI in Quantum, Quantum Machine Learning",1488,2011
"Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions","Matteo Esposito, Xiaozhou Li, Sergio Moreschini, Noman Ahmad, Tomas Cerny, Karthik Vaidhyanathan, Valentina Lenarduzzi, Davide Taibi","Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",http://arxiv.org/abs/2503.13310v1,"context, genai, intelligence, artificial, generative",Machine Learning & AI in Quantum,2566,2011
Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework,"Farnoush Bayatmakou, Reza Taleei, Milad Amir Toutounchian, Arash Mohammadi","Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer remains one of the leading causes of cancer-related deaths among women worldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown significant promise in development of advanced Deep Learning (DL) architectures for breast cancer diagnosis through mammography. In this context, the paper focuses on the integration of AI within a Human-Centric workflow to enhance breast cancer diagnostics. Key challenges are, however, largely overlooked such as reliance on detailed tumor annotations and susceptibility to missing views, particularly during test time. To address these issues, we propose a hybrid, multi-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that enhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework is designed to work as a decision-support tool, helping radiologists analyze multi-view mammograms more effectively. More specifically, the MSMV-Swin framework leverages the Segment Anything Model (SAM) to isolate the breast lobe, reducing background noise and enabling comprehensive feature extraction. The multi-scale nature of the proposed MSMV-Swin framework accounts for tumor-specific regions as well as the spatial characteristics of tissues surrounding the tumor, capturing both localized and contextual information. The integration of contextual and localized data ensures that MSMV-Swin's outputs align with the way radiologists interpret mammograms, fostering better human-AI interaction and trust. A hybrid fusion structure is then designed to ensure robustness against missing views, a common occurrence in clinical practice when only a single mammogram view is available.",http://arxiv.org/abs/2503.13309v1,"aided, advancements, cad, computer, diagnosis",Machine Learning & AI in Quantum,785,2019
From Light-Cone to Supersonic Propagation of Correlations by Competing Short- and Long-Range Couplings,"Catalin-Mihai Halati, Ameneh Sheikhan, Giovanna Morigi, Corinna Kollath, Simon B. J?ger","We investigate the dynamical spreading of correlations in many-body quantum systems with competing short- and global-range couplings. We monitor the non-equilibrium dynamics of the correlations following a quench, showing that for strong short-range couplings the propagation of correlations is dominated at short and intermediate distances by a causal, light-cone, dynamics, resembling the purely short-range quantum systems. However, the interplay of short- and global-range couplings leads to a crossover between space-time regions in which the light-cone persists to regions where a supersonic, distance-independent, spreading of the correlations occurs. We identify the important ingredients needed for capturing the supersonic spreading and demonstrate our findings in systems of interacting bosonic atoms, in which the global range coupling is realized by a coupling to a cavity light field, or atomic long-range interactions, respectively. We show that our results hold in both one and two dimensions and in the presence of dissipation. Furthermore, we characterize the short time power-law scaling of the distance-independent growth of the density-density correlations.",http://arxiv.org/abs/2503.13306v1,"systems, correlations, spreading, quantum, body",Quantum Computing & Information,4024,2010
Computation Mechanism Behind LLM Position Generalization,"Chi Han, Heng Ji","Most written natural languages are composed of sequences of words and sentences. Similar to humans, large language models (LLMs) exhibit flexibility in handling textual positions - a phenomenon we term position generalization. They can understand texts with position perturbations and generalize to longer texts than those encountered during training with the latest techniques. These phenomena suggest that LLMs handle positions tolerantly, but how LLMs computationally process positional relevance remains largely unexplored. This work connects the linguistic phenomenon with LLMs' computational mechanisms. We show how LLMs enforce certain computational mechanisms for the aforementioned tolerance in position perturbations. Despite the complex design of the self-attention mechanism, this work reveals that LLMs learn a counterintuitive disentanglement of attention logits. Their values show a 0.959 linear correlation with an approximation of the arithmetic sum of positional relevance and semantic importance. Furthermore, we identify a prevalent pattern in intermediate features, which we prove theoretically enables this effect. The pattern, which is different from how randomly initialized parameters would behave, suggests that it is a learned behavior rather than a natural result of the model architecture. Based on these findings, we provide computational explanations and criteria for LLMs' position flexibilities. This work takes a pioneering step in linking position generalization with modern LLMs' internal mechanisms.",http://arxiv.org/abs/2503.13305v1,"sentences, languages, words, humans, sequences",Machine Learning & AI in Quantum,44,2025
GFSNetwork: Differentiable Feature Selection via Gumbel-Sigmoid Relaxation,"Witold Wydmanski, Marek Smieja","Feature selection in deep learning remains a critical challenge, particularly for high-dimensional tabular data where interpretability and computational efficiency are paramount. We present GFSNetwork, a novel neural architecture that performs differentiable feature selection through temperature-controlled Gumbel-Sigmoid sampling. Unlike traditional methods, where the user has to define the requested number of features, GFSNetwork selects it automatically during an end-to-end process. Moreover, GFSNetwork maintains constant computational overhead regardless of the number of input features. We evaluate GFSNetwork on a series of classification and regression benchmarks, where it consistently outperforms recent methods including DeepLasso, attention maps, as well as traditional feature selectors, while using significantly fewer features. Furthermore, we validate our approach on real-world metagenomic datasets, demonstrating its effectiveness in high-dimensional biological data. Concluding, our method provides a scalable solution that bridges the gap between neural network flexibility and traditional feature selection interpretability. We share our python implementation of GFSNetwork at https://github.com/wwydmanski/GFSNetwork, as well as a PyPi package (gfs_network).",http://arxiv.org/abs/2503.13304v1,"data, challenge, learning, feature, selection",Quantum Machine Learning,3162,2022
LIMCA: LLM for Automating Analog In-Memory Computing Architecture Design Exploration,"Deepak Vungarala, Md Hasibul Amin, Pietro Mercati, Arnob Ghosh, Arman Roohi, Ramtin Zand, Shaahin Angizi","Resistive crossbars enabling analog In-Memory Computing (IMC) have emerged as a promising architecture for Deep Neural Network (DNN) acceleration, offering high memory bandwidth and in-situ computation. However, the manual, knowledge-intensive design process and the lack of high-quality circuit netlists have significantly constrained design space exploration and optimization to behavioral system-level tools. In this work, we introduce LIMCA, a novel fine-tune-free Large Language Model (LLM)-driven framework for automating the design and evaluation of IMC crossbar architectures. Unlike traditional approaches, LIMCA employs a No-Human-In-Loop (NHIL) automated pipeline to generate and validate circuit netlists for SPICE simulations, eliminating manual intervention. LIMCA systematically explores the IMC design space by leveraging a structured dataset and LLM-based performance evaluation. Our experimental results on MNIST classification demonstrate that LIMCA successfully generates crossbar designs achieving $\geq$96% accuracy while maintaining a power consumption $\leq$3W, making this the first work in LLM-assisted IMC design space exploration. Compared to existing frameworks, LIMCA provides an automated, scalable, and hardware-aware solution, reducing design exploration time while ensuring user-constrained performance trade-offs.",http://arxiv.org/abs/2503.13301v1,"crossbars, computing, in, analog, memory",Quantum Hardware & Circuits,1965,2024
A Survey on Transformer Context Extension: Approaches and Evaluation,"Yijun Liu, Jinzheng Yu, Yang Xu, Zhongyang Li, Qingfu Zhu","Large language models (LLMs) based on Transformer have been widely applied in the filed of natural language processing (NLP), demonstrating strong performance, particularly in handling short text tasks. However, when it comes to long context scenarios, the performance of LLMs degrades due to some challenges. To alleviate this phenomenon, there is a number of work proposed recently. In this survey, we first list the challenges of applying pre-trained LLMs to process long contexts. Then systematically review the approaches related to long context and propose our taxonomy categorizing them into four main types: positional encoding, context compression, retrieval augmented, and attention pattern. In addition to the approaches, we focus on the evaluation of long context, organizing relevant data, tasks, and metrics based on existing long context benchmarks. Finally, we summarize unresolved issues in the long context domain and put forward our views on future developments.",http://arxiv.org/abs/2503.13299v1,"models, language, transformer, llms",Machine Learning & AI in Quantum,1595,2006
On Local Posterior Structure in Deep Ensembles,"Mikkel Jordahn, Jonas Vestergaard Jensen, Mikkel N. Schmidt, Michael Riis Andersen","Bayesian Neural Networks (BNNs) often improve model calibration and predictive uncertainty quantification compared to point estimators such as maximum-a-posteriori (MAP). Similarly, deep ensembles (DEs) are also known to improve calibration, and therefore, it is natural to hypothesize that deep ensembles of BNNs (DE-BNNs) should provide even further improvements. In this work, we systematically investigate this across a number of datasets, neural network architectures, and BNN approximation methods and surprisingly find that when the ensembles grow large enough, DEs consistently outperform DE-BNNs on in-distribution data. To shine light on this observation, we conduct several sensitivity and ablation studies. Moreover, we show that even though DE-BNNs outperform DEs on out-of-distribution metrics, this comes at the cost of decreased in-distribution performance. As a final contribution, we open-source the large pool of trained models to facilitate further research on this topic.",http://arxiv.org/abs/2503.13296v1,"neural, bnns, networks, model, bayesian",Quantum Machine Learning,3953,2000
Realization of fermionic Laughlin state on a quantum processor,"Lingnan Shen, Mao Lin, Cedric Yen-Yu Lin, Di Xiao, Ting Cao","Strongly correlated topological phases of matter are central to modern condensed matter physics and quantum information technology but often challenging to probe and control in material systems. The experimental difficulty of accessing these phases has motivated the use of engineered quantum platforms for simulation and manipulation of exotic topological states. Among these, the Laughlin state stands as a cornerstone for topological matter, embodying fractionalization, anyonic excitations, and incompressibility. Although its bosonic analogs have been realized on programmable quantum simulators, a genuine fermionic Laughlin state has yet to be demonstrated on a quantum processor. Here, we realize the {\nu} = 1/3 fermionic Laughlin state on IonQ's Aria-1 trapped-ion quantum computer using an efficient and scalable Hamiltonian variational ansatz with 369 two-qubit gates on a 16-qubit circuit. Employing symmetry-verification error mitigation, we extract key observables that characterize the Laughlin state, including correlation hole and chiral edge modes, with strong agreement to exact diagonalization benchmarks. This work establishes a scalable quantum framework to simulate material-intrinsic topological orders and provides a starting point to explore its dynamics and excitations on digital quantum processors.",http://arxiv.org/abs/2503.13294v1,"phases, quantum, matter, physics",Quantum Computing & Information,3083,2000
$f$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation,"Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu","Inference-time optimization scales computation to derive deliberate reasoning steps for effective performance. While previous search-based strategies address the short-sightedness of auto-regressive generation, the vast search space leads to excessive exploration and insufficient exploitation. To strike an efficient balance to derive the optimal step, we frame the decoding strategy as foresight sampling, leveraging simulated future steps to obtain globally optimal step estimation. Built on it, we propose a novel decoding strategy, named $\phi$-Decoding. To provide a precise and expressive estimation of step value, $\phi$-Decoding approximates two distributions via foresight and clustering. Sampling from the joint distribution, the optimal steps can be selected for exploitation. To support adaptive computation allocation, we propose in-width and in-depth pruning strategies, featuring a light-weight solution to achieve inference efficiency. Extensive experiments across seven benchmarks show $\phi$-Decoding outperforms strong baselines in both performance and efficiency. Additional analysis demonstrates its generalization across various LLMs and scalability across a wide range of computing budgets. The code will be released at https://github.com/xufangzhi/phi-Decoding, and the open-source PyPI package is coming soon.",http://arxiv.org/abs/2503.13288v1,"optimization, computation, reasoning, inference, time","Quantum Machine Learning, Machine Learning & AI in Quantum",1031,2024
Low-loss Nb on Si superconducting resonators from a dual-use spintronics deposition chamber and with acid-free post-processing,"Maciej W. Olszewski, Jadrien T. Paustian, Tathagata Banerjee, Haoran Lu, Jorge L. Ramirez, Nhi Nguyen, Kiichi Okubo, Rohit Pant, Aleksandra B. Biedron, Daniel C. Ralph, Christopher J. K. Richardson, Gregory D. Fuchs, Corey Rae H. McRae, Ivan V. Pechenezhskiy, B. L. T. Plourde, Valla Fatemi","Magnetic impurities are known to degrade superconductivity. For this reason, physical vapor deposition chambers that have previously been used for magnetic materials have generally been avoided for making high-quality superconducting resonator devices. In this article, we show by example that such chambers can be used: with Nb films sputtered in a chamber that continues to be used for magnetic materials, we demonstrate compact (3 {\mu}m gap) coplanar waveguide resonators with low-power internal quality factors near one million. We achieve this using a resist strip bath with no post-fabrication acid treatment, which results in performance comparable to previous strip baths with acid treatments. We also find evidence that this improved resist strip bath provides a better surface chemical template for post-fabrication hydrogen fluoride processing. These results are consistent across three Si substrate preparation methods, including a \SI{700}{\celsius} anneal.",http://arxiv.org/abs/2503.13285v1,"superconductivity, impurities, reason, deposition, vapor",Quantum Computing & Information,3471,2024
Quantum bounds and device-independent security with rank-one qubit measurements,"Lorenzo Coccia, Matteo Padovan, Andrea Pompermaier, Mattia Sabatini, Marco Avesani, Davide Giacomo Marangon, Paolo Villoresi, Giuseppe Vallone","Device-independent (DI) quantum protocols exploit Bell inequality violations to ensure security or certify quantum properties without making assumptions about the internal workings of the devices. In this work, we study the role of rank-one qubit positive operator-valued measures (POVMs) in DI scenarios. This class includes all qubit extremal POVMs, i.e., those measurements that cannot be realized by randomly choosing among others, as well as part of non-extremal POVMs, which have recently been shown to be useful for security applications in sequential quantum protocols. We demonstrate that any rank-one POVM can generate correlations in bipartite scenarios that saturate a Tsirelson inequality, i.e., a quantum bound on linear combinations of outcome statistics, when the two parties share an arbitrary entangled two-qubit state and some other self-tested measurements are performed. For extremal POVMs, such saturation allows for an explicit calculation of the guessing probability and the worst-case conditional von Neumann entropy. From the Tsirelson inequality, we establish a randomness certification method that facilitates numerical simulations and noise analysis. To test its feasibility, we performed a proof-of-concept experiment employing a three-outcome POVM on tilted entangled states under experimental non-idealities. We further explore the case of non-extremal POVMs, providing insights into their role in DI protocols.",http://arxiv.org/abs/2503.13282v1,"bell, device, protocols, quantum, di",Quantum Computing & Information,2623,2019
LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation,"Xiaodi Li, Shaika Chowdhury, Chung Il Wi, Maria Vassilaki, Ken Liu, Terence T Sio, Owen Garrick, Young J Juhn, James R Cerhan, Cui Tao, Nansu Zong","Patient matching is the process of linking patients to appropriate clinical trials by accurately identifying and matching their medical records with trial eligibility criteria. We propose LLM-Match, a novel framework for patient matching leveraging fine-tuned open-source large language models. Our approach consists of four key components. First, a retrieval-augmented generation (RAG) module extracts relevant patient context from a vast pool of electronic health records (EHRs). Second, a prompt generation module constructs input prompts by integrating trial eligibility criteria (both inclusion and exclusion criteria), patient context, and system instructions. Third, a fine-tuning module with a classification head optimizes the model parameters using structured prompts and ground-truth labels. Fourth, an evaluation module assesses the fine-tuned model's performance on the testing datasets. We evaluated LLM-Match on four open datasets, n2c2, SIGIR, TREC 2021, and TREC 2022, using open-source models, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed models. LLM-Match outperformed all baselines.",http://arxiv.org/abs/2503.13281v1,"trials, matching, process, patient, patients","Machine Learning & AI in Quantum, Quantum Machine Learning",3853,2012
Artificial Intelligence-Driven Prognostic Classification of COVID-19 Using Chest X-rays: A Deep Learning Approach,"Alfred Simbun, Suresh Kumar","Background: The COVID-19 pandemic has overwhelmed healthcare systems, emphasizing the need for AI-driven tools to assist in rapid and accurate patient prognosis. Chest X-ray imaging is a widely available diagnostic tool, but existing methods for prognosis classification lack scalability and efficiency. Objective: This study presents a high-accuracy deep learning model for classifying COVID-19 severity (Mild, Moderate, and Severe) using Chest X-ray images, developed on Microsoft Azure Custom Vision. Methods: Using a dataset of 1,103 confirmed COVID-19 X-ray images from AIforCOVID, we trained and validated a deep learning model leveraging Convolutional Neural Networks (CNNs). The model was evaluated on an unseen dataset to measure accuracy, precision, and recall. Results: Our model achieved an average accuracy of 97%, with specificity of 99%, sensitivity of 87%, and an F1-score of 93.11%. When classifying COVID-19 severity, the model achieved accuracies of 89.03% (Mild), 95.77% (Moderate), and 81.16% (Severe). These results demonstrate the model's potential for real-world clinical applications, aiding in faster decision-making and improved resource allocation. Conclusion: AI-driven prognosis classification using deep learning can significantly enhance COVID-19 patient management, enabling early intervention and efficient triaging. Our study provides a scalable, high-accuracy AI framework for integrating deep learning into routine clinical workflows. Future work should focus on expanding datasets, external validation, and regulatory compliance to facilitate clinical adoption.",http://arxiv.org/abs/2503.13277v1,"systems, covid-19, need, healthcare, background",Machine Learning & AI in Quantum,1510,2008
Graph Generative Models Evaluation with Masked Autoencoder,"Chengen Wang, Murat Kantarcioglu","In recent years, numerous graph generative models (GGMs) have been proposed. However, evaluating these models remains a considerable challenge, primarily due to the difficulty in extracting meaningful graph features that accurately represent real-world graphs. The traditional evaluation techniques, which rely on graph statistical properties like node degree distribution, clustering coefficients, or Laplacian spectrum, overlook node features and lack scalability. There are newly proposed deep learning-based methods employing graph random neural networks or contrastive learning to extract graph features, demonstrating superior performance compared to traditional statistical methods, but their experimental results also demonstrate that these methods do not always working well across different metrics. Although there are overlaps among these metrics, they are generally not interchangeable, each evaluating generative models from a different perspective. In this paper, we propose a novel method that leverages graph masked autoencoders to effectively extract graph features for GGM evaluations. We conduct extensive experiments on graphs and empirically demonstrate that our method can be more reliable and effective than previously proposed methods across a number of GGM evaluation metrics, such as ""Fr\'echet Distance (FD)"" and ""MMD Linear"". However, no single method stands out consistently across all metrics and datasets. Therefore, this study also aims to raise awareness of the significance and challenges associated with GGM evaluation techniques, especially in light of recent advances in generative models.",http://arxiv.org/abs/2503.13271v1,"models, years, graph, ggms",Quantum Machine Learning,4808,2002
Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning,"Tianxing Fu, Jia Hu, Geyong Min, Zi Wang","Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",http://arxiv.org/abs/2503.13255v1,"learning, participants, machine, federated, fl",Quantum Cryptography & Security,171,2006
Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning,"Akshay Thakur, Matthew J. Zahr","The Riemann problem is fundamental in the computational modeling of hyperbolic partial differential equations, enabling the development of stable and accurate upwind schemes. While exact solvers provide robust upwinding fluxes, their high computational cost necessitates approximate solvers. Although approximate solvers achieve accuracy in many scenarios, they produce inaccurate solutions in certain cases. To overcome this limitation, we propose constructing neural network-based surrogate models, trained using supervised learning, designed to map interior and exterior conservative state variables to the corresponding exact flux. Specifically, we propose two distinct approaches: one utilizing a vanilla neural network and the other employing a bi-fidelity neural network. The performance of the proposed approaches is demonstrated through applications to one-dimensional and two-dimensional partial differential equations, showcasing their robustness and accuracy.",http://arxiv.org/abs/2503.13248v1,"problem, equations, modeling, riemann, development",Quantum Machine Learning,4307,2005
Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression,"Guoyou Sun, Panagiotis Karras, Qi Zhang","Semantic communication has emerged as a promising paradigm to tackle the challenges of massive growing data traffic and sustainable data communication. It shifts the focus from data fidelity to goal-oriented or task-oriented semantic transmission. While deep learning-based methods are commonly used for semantic encoding and decoding, they struggle with the sequential nature of time series data and high computation cost, particularly in resource-constrained IoT environments. Data compression plays a crucial role in reducing transmission and storage costs, yet traditional data compression methods fall short of the demands of goal-oriented communication systems. In this paper, we propose a novel method for direct analytics on time series data compressed by the SHRINK compression algorithm. Through experimentation using outlier detection as a case study, we show that our method outperforms baselines running on uncompressed data in multiple cases, with merely 1% difference in the worst case. Additionally, it achieves four times lower runtime on average and accesses approximately 10% of the data volume, which enables edge analytics with limited storage and computation power. These results demonstrate that our approach offers reliable, high-speed outlier detection analytics for diverse IoT applications while extracting semantics from time-series data, achieving high compression, and reducing data transmission.",http://arxiv.org/abs/2503.13246v1,"data, paradigm, challenges, traffic, communication",Quantum Machine Learning,1991,2007
Gradient Extrapolation for Debiased Representation Learning,"Ihab Asaad, Maha Shadaydeh, Joachim Denzler","Machine learning classification models trained with empirical risk minimization (ERM) often inadvertently rely on spurious correlations. When absent in the test data, these unintended associations between non-target attributes and target labels lead to poor generalization. This paper addresses this problem from a model optimization perspective and proposes a novel method, Gradient Extrapolation for Debiased Representation Learning (GERNE), designed to learn debiased representations in both known and unknown attribute training cases. GERNE uses two distinct batches with different amounts of spurious correlations to define the target gradient as the linear extrapolation of two gradients computed from each batch's loss. It is demonstrated that the extrapolated gradient, if directed toward the gradient of the batch with fewer amount of spurious correlation, can guide the training process toward learning a debiased model. GERNE can serve as a general framework for debiasing with methods, such as ERM, reweighting, and resampling, being shown as special cases. The theoretical upper and lower bounds of the extrapolation factor are derived to ensure convergence. By adjusting this factor, GERNE can be adapted to maximize the Group-Balanced Accuracy (GBA) or the Worst-Group Accuracy. The proposed approach is validated on five vision and one NLP benchmarks, demonstrating competitive and often superior performance compared to state-of-the-art baseline methods.",http://arxiv.org/abs/2503.13236v1,"classification, models, risk, machine, minimization",Quantum Machine Learning,1005,2008
Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch,"Yijie Liu, Xinyi Shang, Yiqun Zhang, Yang Lu, Chen Gong, Jing-Hao Xue, Hanzi Wang","Federated Semi-Supervised Learning (FSSL) aims to leverage unlabeled data across clients with limited labeled data to train a global model with strong generalization ability. Most FSSL methods rely on consistency regularization with pseudo-labels, converting predictions from local or global models into hard pseudo-labels as supervisory signals. However, we discover that the quality of pseudo-label is largely deteriorated by data heterogeneity, an intrinsic facet of federated learning. In this paper, we study the problem of FSSL in-depth and show that (1) heterogeneity exacerbates pseudo-label mismatches, further degrading model performance and convergence, and (2) local and global models' predictive tendencies diverge as heterogeneity increases. Motivated by these findings, we propose a simple and effective method called Semi-supervised Aggregation for Globally-Enhanced Ensemble (SAGE), that can flexibly correct pseudo-labels based on confidence discrepancies. This strategy effectively mitigates performance degradation caused by incorrect pseudo-labels and enhances consensus between local and global models. Experimental results demonstrate that SAGE outperforms existing FSSL methods in both performance and convergence. Our code is available at https://github.com/Jay-Codeman/SAGE",http://arxiv.org/abs/2503.13227v1,"data, learning, fssl, federated, semi",Quantum Machine Learning,4921,2004
Optimizing the frequency positioning of tunable couplers in a circuit QED processor to mitigate spectator effects on quantum operations,"S. Vall?s-Sanclemente, T. H. F. Vroomans, T. R. van Abswoude, F. Brulleman, T. Stavenga, S. L. M. van der Meer, Y. Xin, A. Lawrence, V. Singh, M. A. Rol, L. DiCarlo","We experimentally optimize the frequency of flux-tunable couplers in a superconducting quantum processor to minimize the impact of spectator transmons during quantum operations (single-qubit gates, two-qubit gates and readout) on other transmons. We adapt a popular transmon-like tunable-coupling element, achieving high-fidelity, low-leakage controlled-$Z$ gates with unipolar, fast-adiabatic pulsing only on the coupler. We demonstrate the ability of the tunable coupler to null residual $ZZ$ coupling as well as exchange couplings in the one- and two-excitation manifolds. However, the nulling of these coherent interactions is not simultaneous, prompting the exploration of tradeoffs. We present experiments pinpointing spectator effects on specific quantum operations. We also study the combined effect on the three types of operations using repeated quantum parity measurements.",http://arxiv.org/abs/2503.13225v1,"couplers, flux, tunable, quantum, frequency",Quantum Computing & Information,3352,2000
ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction,"Tong Zhou, Shijin Duan, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu","Pre-trained models are valuable intellectual property, capturing both domain-specific and domain-invariant features within their weight spaces. However, model extraction attacks threaten these assets by enabling unauthorized source-domain inference and facilitating cross-domain transfer via the exploitation of domain-invariant features. In this work, we introduce **ProDiF**, a novel framework that leverages targeted weight space manipulation to secure pre-trained models against extraction attacks. **ProDiF** quantifies the transferability of filters and perturbs the weights of critical filters in unsecured memory, while preserving actual critical weights in a Trusted Execution Environment (TEE) for authorized users. A bi-level optimization further ensures resilience against adaptive fine-tuning attacks. Experimental results show that **ProDiF** reduces source-domain accuracy to near-random levels and decreases cross-domain transferability by 74.65\%, providing robust protection for pre-trained models. This work offers comprehensive protection for pre-trained DNN models and highlights the potential of weight space manipulation as a novel approach to model security.",http://arxiv.org/abs/2503.13224v1,"models, features, domain, property","Quantum Cryptography & Security, Quantum Machine Learning",4561,2018
Can Language Models Follow Multiple Turns of Entangled Instructions?,Chi Han,"Despite significant achievements in improving the instruction-following capabilities of large language models (LLMs), the ability to process multiple potentially entangled or conflicting instructions remains a considerable challenge. Real-world scenarios often require consistency across multiple instructions over time, such as secret privacy, personal preferences, and prioritization, which demand sophisticated abilities to integrate multiple turns and carefully balance competing objectives when instructions intersect or conflict. This work presents a systematic investigation of LLMs' capabilities in handling multiple turns of instructions, covering three levels of difficulty: (1) retrieving information from instructions, (2) tracking and reasoning across turns, and (3) resolving conflicts among instructions. We construct MultiTurnInstruct with around 1.1K high-quality multi-turn conversations through the human-in-the-loop approach and result in nine capability categories, including statics and dynamics, reasoning, and multitasking. Our finding reveals an intriguing trade-off between different capabilities. While GPT models demonstrate superior memorization, they show reduced effectiveness in privacy-protection tasks requiring selective information withholding. Larger models exhibit stronger reasoning capabilities but still struggle with resolving conflicting instructions. Importantly, these performance gaps cannot be attributed solely to information loss, as models demonstrate strong BLEU scores on memorization tasks but their attention mechanisms fail to integrate multiple related instructions effectively. These findings highlight critical areas for improvement in complex real-world tasks involving multi-turn instructions.",http://arxiv.org/abs/2503.13222v1,"capabilities, instruction, models, achievements, language",Machine Learning & AI in Quantum,3808,2009
Simulating Raman Scattering Impairments with Depolarization Noise in Quantum-Classical Links,"Jake Smith, Roberto Proietti","We model spontaneous Raman scattering noise in polarization-encoded quantum communication channels co-propagating with classical signals using the depolarization channel. Utilizing NetSquid simulations, we validate the model against demonstrations of qubit transmission, entanglement distribution, and teleportation.",http://arxiv.org/abs/2503.13220v1,"polarization, signals, noise, channels, communication",Quantum Computing & Information,1285,2011
Dense Policy: Bidirectional Autoregressive Learning of Actions,"Yue Su, Xinyu Zhan, Hongjie Fang, Han Xue, Hao-Shu Fang, Yong-Lu Li, Cewu Lu, Lixin Yang","Mainstream visuomotor policies predominantly rely on generative models for holistic action prediction, while current autoregressive policies, predicting the next token or chunk, have shown suboptimal results. This motivates a search for more effective learning methods to unleash the potential of autoregressive policies for robotic manipulation. This paper introduces a bidirectionally expanded learning approach, termed Dense Policy, to establish a new paradigm for autoregressive policies in action prediction. It employs a lightweight encoder-only architecture to iteratively unfold the action sequence from an initial single frame into the target sequence in a coarse-to-fine manner with logarithmic-time inference. Extensive experiments validate that our dense policy has superior autoregressive learning capabilities and can surpass existing holistic generative policies. Our policy, example data, and training code will be publicly available upon publication. Project page: https: //selen-suyue.github.io/DspNet/.",http://arxiv.org/abs/2503.13217v1,"policies, models, visuomotor, mainstream, action",Quantum Machine Learning,1026,2023
A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening,"Jie Huang, Haorui Chen, Jiaxuan Ren, Siran Peng, Liangjian Deng","Currently, deep learning-based methods for remote sensing pansharpening have advanced rapidly. However, many existing methods struggle to fully leverage feature heterogeneity and redundancy, thereby limiting their effectiveness. We use the covariance matrix to model the feature heterogeneity and redundancy and propose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW captures these correlations through the covariance matrix, which is then processed by a nonlinear function to generate weights for adjustment. Building upon CACW, we introduce a general adaptive dual-level weighting mechanism (ADWM) to address these challenges from two key perspectives, enhancing a wide range of existing deep-learning methods. First, Intra-Feature Weighting (IFW) evaluates correlations among channels within each feature to reduce redundancy and enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts contributions across layers based on inter-layer correlations, refining the final output. Extensive experiments demonstrate the superior performance of ADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we validate the effectiveness of our approach through generality experiments, redundancy visualization, comparison experiments, key variables and complexity analysis, and ablation studies. Our code is available at https://github.com/Jie-1203/ADWM.",http://arxiv.org/abs/2503.13214v1,"pansharpening, methods, learning, sensing",Machine Learning & AI in Quantum,347,2014
MAME: Multidimensional Adaptive Metamer Exploration with Human Perceptual Feedback,"Mina Kamao, Hayato Ono, Ayumu Yamashita, Kaoru Amano, Masataka Sawayama","Alignment between human brain networks and artificial models is actively studied in machine learning and neuroscience. A widely adopted approach to explore their functional alignment is to identify metamers for both humans and models. Metamers refer to input stimuli that are physically different but equivalent within a given system. If a model's metameric space completely matched the human metameric space, the model would achieve functional alignment with humans. However, conventional methods lack direct ways to search for human metamers. Instead, researchers first develop biologically inspired models and then infer about human metamers indirectly by testing whether model metamers also appear as metamers to humans. Here, we propose the Multidimensional Adaptive Metamer Exploration (MAME) framework, enabling direct high-dimensional exploration of human metameric space. MAME leverages online image generation guided by human perceptual feedback. Specifically, it modulates reference images across multiple dimensions by leveraging hierarchical responses from convolutional neural networks (CNNs). Generated images are presented to participants whose perceptual discriminability is assessed in a behavioral task. Based on participants' responses, subsequent image generation parameters are adaptively updated online. Using our MAME framework, we successfully measured a human metameric space of over fifty dimensions within a single experiment. Experimental results showed that human discrimination sensitivity was lower for metameric images based on low-level features compared to high-level features, which image contrast metrics could not explain. The finding suggests that the model computes low-level information not essential for human perception. Our framework has the potential to contribute to developing interpretable AI and understanding of brain function in neuroscience.",http://arxiv.org/abs/2503.13212v1,"brain, models, networks, alignment, machine",Quantum Machine Learning,888,2021
MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis,"Marvin Seyfarth, Salman Ul Hassan Dar, Isabelle Ayx, Matthias Alexander Fink, Stefan O. Schoenberg, Hans-Ulrich Kauczor, Sandy Engelhardt","Advancements in AI for medical imaging offer significant potential. However, their applications are constrained by the limited availability of data and the reluctance of medical centers to share it due to patient privacy concerns. Generative models present a promising solution by creating synthetic data as a substitute for real patient data. However, medical images are typically high-dimensional, and current state-of-the-art methods are often impractical for computational resource-constrained healthcare environments. These models rely on data sub-sampling, raising doubts about their feasibility and real-world applicability. Furthermore, many of these models are evaluated on quantitative metrics that alone can be misleading in assessing the image quality and clinical meaningfulness of the generated images. To address this, we introduce MedLoRD, a generative diffusion model designed for computational resource-constrained environments. MedLoRD is capable of generating high-dimensional medical volumes with resolutions up to 512$\times$512$\times$256, utilizing GPUs with only 24GB VRAM, which are commonly found in standard desktop workstations. MedLoRD is evaluated across multiple modalities, including Coronary Computed Tomography Angiography and Lung Computed Tomography datasets. Extensive evaluations through radiological evaluation, relative regional volume analysis, adherence to conditional masks, and downstream tasks show that MedLoRD generates high-fidelity images closely adhering to segmentation mask conditions, surpassing the capabilities of current state-of-the-art generative models for medical image synthesis in computational resource-constrained environments.",http://arxiv.org/abs/2503.13211v1,"applications, advancements, potential, ai, imaging",Machine Learning & AI in Quantum,1086,2023
Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach,"Sinan Fan, Liang Xie, Chen Shen, Ge Teng, Xiaosong Yuan, Xiaofeng Zhang, Chenxi Huang, Wenxiao Wang, Xiaofei He, Jieping Ye","Prompt-tuning (PT) for large language models (LLMs) can facilitate the performance on various conventional NLP tasks with significantly fewer trainable parameters. However, our investigation reveals that PT provides limited improvement and may even degrade the primitive performance of LLMs on complex reasoning tasks. Such a phenomenon suggests that soft prompts can positively impact certain instances while negatively affecting others, particularly during the later phases of reasoning. To address these challenges, We first identify an information accumulation within the soft prompts. Through detailed analysis, we demonstrate that this phenomenon is often accompanied by erroneous information flow patterns in the deeper layers of the model, which ultimately lead to incorrect reasoning outcomes. we propose a novel method called \textbf{D}ynamic \textbf{P}rompt \textbf{C}orruption (DPC) to take better advantage of soft prompts in complex reasoning tasks, which dynamically adjusts the influence of soft prompts based on their impact on the reasoning process. Specifically, DPC consists of two stages: Dynamic Trigger and Dynamic Corruption. First, Dynamic Trigger measures the impact of soft prompts, identifying whether beneficial or detrimental. Then, Dynamic Corruption mitigates the negative effects of soft prompts by selectively masking key tokens that interfere with the reasoning process. We validate the proposed approach through extensive experiments on various LLMs and reasoning tasks, including GSM8K, MATH, and AQuA. Experimental results demonstrate that DPC can consistently enhance the performance of PT, achieving 4\%-8\% accuracy gains compared to vanilla prompt tuning, highlighting the effectiveness of our approach and its potential to enhance complex reasoning in LLMs.",http://arxiv.org/abs/2503.13208v1,"pt, models, llms, tuning, language",Machine Learning & AI in Quantum,4897,2008
Non-asymptotic quantum communication on lossy transmission lines with memory,"Francesco Anna Mele, Giovanni Barbarino, Vittorio Giovannetti, Marco Fanizza","Non-asymptotic quantum Shannon theory analyses how to transmit quantum information across a quantum channel as efficiently as possible within a specified error tolerance, given access to a finite, fixed, number of channel uses. In a recent work, we derived computable lower bounds on the non-asymptotic capacities of memoryless bosonic Gaussian channels. In this work, we extend these results to the non-Markovian bosonic Gaussian channel introduced in F. A. Mele, G. D. Palma, M. Fanizza, V. Giovannetti, and L. Lami IEEE Transactions on Information Theory 70(12), 8844-8869 (2024), which describes non-Markovian effects in optical fibres and is a non-Markovian generalisation of the pure loss channel. This allows us to determine how many uses of a non-Markovian optical fibre are sufficient in order to transmit $k$ qubits, distil $k$ ebits, or generate $k$ secret-key bits up to a given error tolerance $\varepsilon$. To perform our analysis, we prove novel properties of singular values of Toeplitz matrices, providing an error bound on the convergence rate of the celebrated Avram-Parter's theorem, which we regard as a new tool of independent interest for the field of quantum information theory and matrix analysis.",http://arxiv.org/abs/2503.13207v1,"information, theory, channel, quantum, shannon",Quantum Computing & Information,4003,2019
Enhanced Quantum Signal Control and Sensing Under Multicolored Noise via Generalized Filter Function Framework,"Zhi-Da Zhang, Yao Song, Wen-Zheng Dong, Xiu-Hao Deng","We introduce a generalized filter-function framework that treats noise coupling strength as a tunable control parameter, enabling target noise suppression across user-defined frequency bands. By optimizing this generalized filter function, we design band-selective control pulses that achieve $0.9999$ fidelity of single- and two-qubit gates under strong noise with diverse spectral profiles. We further extend the method to selectively enhance the signal-to-noise ratio for quantum sensing of AC signals with an enhanced precision of up to $10$ dB. The resulting control pulses are experimentally feasible, offering a practical pathway toward robust quantum operations and high-precision signal processing under spectrally complex noises.",http://arxiv.org/abs/2503.13206v1,"function, noise, filter, framework, coupling",Quantum Computing & Information,4869,2016
MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways,"Zhen Chen, Zhihao Peng, Xusheng Liang, Cheng Wang, Peigan Liang, Linsheng Zeng, Minjie Ju, Yixuan Yuan","Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited research focused on artificial intelligence (AI) inpatient pathways systems, due to the lack of large-scale inpatient datasets. Moreover, existing medical benchmarks typically concentrated on medical question-answering and examinations, ignoring the multifaceted nature of clinical decision-making in inpatient settings. To address these gaps, we first developed the Inpatient Pathway Decision Support (IPDS) benchmark from the MIMIC-IV database, encompassing 51,274 cases across nine triage departments and 17 major disease categories alongside 16 standardized treatment options. Then, we proposed the Multi-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways with three clinical agents, including a triage agent managing the patient admission, a diagnosis agent serving as the primary decision maker at the department, and a treatment agent providing treatment plans. Additionally, our MAP framework includes a chief agent overseeing the inpatient pathways to guide and promote these three clinician agents. Extensive experiments showed our MAP improved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM HuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant clinical compliance, outperforming three board-certified clinicians by 10%-12%, establishing a foundation for inpatient pathways systems.",http://arxiv.org/abs/2503.13205v1,"information, making, challenges, decision, pathways",Machine Learning & AI in Quantum,389,2016
Cycle-Aware ZZ Crosstalk Mitigation on Quantum Hardware,"Jiayi Zhong, Yuxin Deng","ZZ crosstalk and decoherence hinder superconducting quantum computing. To enhance parallelism in mitigating ZZ crosstalk, we formulate the problem by integrating quantum cycles and two forms of qubit interference. We then propose CAZZO, a Cycle-Aware ZZ crosstalk Optimization algorithm, which uses a timing-based greedy strategy to schedule gates through cycles within quantum circuits. A novel data structure called Time and Distance Dependency Graph is designed to model gate data dependencies and physical distances from quantum topologies for precise scheduling. Additionally, dynamically punching barriers reduces idle time in quantum circuits, further enhancing parallelism. Simulations show a reduction of up to 37.44% in quantum program cycle (14.19% on average) on various NISQ devices with 53 to 127 qubits. Real-device experiments on IBMQ-Brisbane demonstrate significant acceleration in quantum computing while maintaining fidelity.",http://arxiv.org/abs/2503.13204v1,"crosstalk, hinder, computing, quantum, zz",Quantum Computing & Information,502,2025
Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services,"Yiman Bao, Jie Gao, Jinke He, Frans A. Oliehoek, Oded Cats","Efficient timing in ride-matching is crucial for improving the performance of ride-hailing and ride-pooling services, as it determines the number of drivers and passengers considered in each matching process. Traditional batched matching methods often use fixed time intervals to accumulate ride requests before assigning matches. While this approach increases the number of available drivers and passengers for matching, it fails to adapt to real-time supply-demand fluctuations, often leading to longer passenger wait times and driver idle periods. To address this limitation, we propose an adaptive ride-matching strategy using deep reinforcement learning (RL) to dynamically determine when to perform matches based on real-time system conditions. Unlike fixed-interval approaches, our method continuously evaluates system states and executes matching at moments that minimize total passenger wait time. Additionally, we incorporate a potential-based reward shaping (PBRS) mechanism to mitigate sparse rewards, accelerating RL training and improving decision quality. Extensive empirical evaluations using a realistic simulator trained on real-world data demonstrate that our approach outperforms fixed-interval matching strategies, significantly reducing passenger waiting times and detour delays, thereby enhancing the overall efficiency of ride-hailing and ride-pooling systems.",http://arxiv.org/abs/2503.13200v1,"timing, ride, performance, matching","Quantum Machine Learning, Machine Learning & AI in Quantum",2072,2019
Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey,"Haoqi Huang, Ping Wang, Jianhua Pei, Jiacheng Wang, Shahen Alexanian, Dusit Niyato","The rapid expansion of data from diverse sources has made anomaly detection (AD) increasingly essential for identifying unexpected observations that may signal system failures, security breaches, or fraud. As datasets become more complex and high-dimensional, traditional detection methods struggle to effectively capture intricate patterns. Advances in deep learning have made AD methods more powerful and adaptable, improving their ability to handle high-dimensional and unstructured data. This survey provides a comprehensive review of over 180 recent studies, focusing on deep learning-based AD techniques. We categorize and analyze these methods into reconstruction-based and prediction-based approaches, highlighting their effectiveness in modeling complex data distributions. Additionally, we explore the integration of traditional and deep learning methods, highlighting how hybrid approaches combine the interpretability of traditional techniques with the flexibility of deep learning to enhance detection accuracy and model transparency. Finally, we identify open issues and propose future research directions to advance the field of AD. This review bridges gaps in existing literature and serves as a valuable resource for researchers and practitioners seeking to enhance AD techniques using deep learning.",http://arxiv.org/abs/2503.13195v1,"data, detection, anomaly, expansion, sources",Quantum Machine Learning,3894,2011
A representational framework for learning and encoding structurally enriched trajectories in complex agent environments,"Corina Catarau-Cotutiu, Esther Mondragon, Eduardo Alonso","The ability of artificial intelligence agents to make optimal decisions and generalise them to different domains and tasks is compromised in complex scenarios. One way to address this issue has focused on learning efficient representations of the world and on how the actions of agents affect them, such as disentangled representations that exploit symmetries. Whereas such representations are procedurally efficient, they are based on the compression of low-level state-action transitions, which lack structural richness. To address this problem, we propose to enrich the agent's ontology and extend the traditional conceptualisation of trajectories to provide a more nuanced view of task execution. Structurally Enriched Trajectories (SETs) extend the encoding of sequences of states and their transitions by incorporating hierarchical relations between objects, interactions and affordances. SETs are built as multi-level graphs, providing a detailed representation of the agent dynamics and a transferable functional abstraction of the task. SETs are integrated into an architecture, Structurally Enriched Trajectory Learning and Encoding (SETLE), that employs a heterogeneous graph-based memory structure of multi-level relational dependencies essential for generalisation. Using reinforcement learning as a data generation tool, we demonstrate that SETLE can support downstream tasks, enabling agents to recognise task-relevant structural patterns across diverse environments.",http://arxiv.org/abs/2503.13194v1,"decisions, agents, intelligence, ability, domains","Machine Learning & AI in Quantum, Quantum Machine Learning",74,2006
3DAxisPrompt: Promoting the 3D Grounding and Reasoning in GPT-4o,"Dingning Liu, Cheng Wang, Peng Gao, Renrui Zhang, Xinzhu Ma, Yuan Meng, Zhihui Wang","Multimodal Large Language Models (MLLMs) exhibit impressive capabilities across a variety of tasks, especially when equipped with carefully designed visual prompts. However, existing studies primarily focus on logical reasoning and visual understanding, while the capability of MLLMs to operate effectively in 3D vision remains an ongoing area of exploration. In this paper, we introduce a novel visual prompting method, called 3DAxisPrompt, to elicit the 3D understanding capabilities of MLLMs in real-world scenes. More specifically, our method leverages the 3D coordinate axis and masks generated from the Segment Anything Model (SAM) to provide explicit geometric priors to MLLMs and then extend their impressive 2D grounding and reasoning ability to real-world 3D scenarios. Besides, we first provide a thorough investigation of the potential visual prompting formats and conclude our findings to reveal the potential and limits of 3D understanding capabilities in GPT-4o, as a representative of MLLMs. Finally, we build evaluation environments with four datasets, i.e., ScanRefer, ScanNet, FMB, and nuScene datasets, covering various 3D tasks. Based on this, we conduct extensive quantitative and qualitative experiments, which demonstrate the effectiveness of the proposed method. Overall, our study reveals that MLLMs, with the help of 3DAxisPrompt, can effectively perceive an object's 3D position in real-world scenarios. Nevertheless, a single prompt engineering approach does not consistently achieve the best outcomes for all 3D tasks. This study highlights the feasibility of leveraging MLLMs for 3D vision grounding/reasoning with prompt engineering techniques.",http://arxiv.org/abs/2503.13185v1,"capabilities, mllms, models, variety, language",Machine Learning & AI in Quantum,2578,2001
GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation,"Jungwon Seo, Ferhat Ozgur Catak, Chunming Rong, Kibeom Hong, Minhoe Kim","Multi-source information fusion (MSIF) leverages diverse data streams to enhance decision-making, situational awareness, and system resilience. Federated Learning (FL) enables MSIF while preserving privacy but suffers from client drift under high data heterogeneity, leading to performance degradation. Traditional mitigation strategies rely on reference-based gradient adjustments, which can be unstable in partial participation settings. To address this, we propose Gradient Centralized Federated Learning (GC-Fed), a reference-free gradient correction method inspired by Gradient Centralization (GC). We introduce Local GC and Global GC, applying GC during local training and global aggregation, respectively. Our hybrid GC-Fed approach selectively applies GC at the feature extraction layer locally and at the classifier layer globally, improving training stability and model performance. Theoretical analysis and empirical results demonstrate that GC-Fed mitigates client drift and achieves state-of-the-art accuracy gains of up to 20% in heterogeneous settings.",http://arxiv.org/abs/2503.13180v1,"data, information, msif, fusion, leverages","Quantum Machine Learning, Machine Learning & AI in Quantum",2037,2002
Rapfi: Distilling Efficient Neural Network for the Game of Gomoku,"Zhanggen Jin, Haobin Duan, Zhiyang Hang","Games have played a pivotal role in advancing artificial intelligence, with AI agents using sophisticated techniques to compete. Despite the success of neural network based game AIs, their performance often requires significant computational resources. In this paper, we present Rapfi, an efficient Gomoku agent that outperforms CNN-based agents in limited computation environments. Rapfi leverages a compact neural network with a pattern-based codebook distilled from CNNs, and an incremental update scheme that minimizes computation when input changes are minor. This new network uses computation that is orders of magnitude less to reach a similar accuracy of much larger neural networks such as Resnet. Thanks to our incremental update scheme, depth-first search methods such as the alpha-beta search can be significantly accelerated. With a carefully tuned evaluation and search, Rapfi reached strength surpassing Katagomo, the strongest open-source Gomoku AI based on AlphaZero's algorithm, under limited computational resources where accelerators like GPUs are absent. Rapfi ranked first among 520 Gomoku agents on Botzone and won the championship in GomoCup 2024.",http://arxiv.org/abs/2503.13178v1,"agents, ai, intelligence, games, role","Machine Learning & AI in Quantum, Quantum Machine Learning",2705,2016
PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning,"Ori Peleg, Natalie Lang, Stefano Rini, Nir Shlezinger, Kobi Cohen","Federated learning (FL) enables multiple edge devices to collaboratively train a machine learning model without the need to share potentially private data. Federated learning proceeds through iterative exchanges of model updates, which pose two key challenges: First, the accumulation of privacy leakage over time, and second, communication latency. These two limitations are typically addressed separately: The former via perturbed updates to enhance privacy and the latter using user selection to mitigate latency - both at the expense of accuracy. In this work, we propose a method that jointly addresses the accumulation of privacy leakage and communication latency via active user selection, aiming to improve the trade-off among privacy, latency, and model performance. To achieve this, we construct a reward function that accounts for these three objectives. Building on this reward, we propose a multi-armed bandit (MAB)-based algorithm, termed Privacy-aware Active User SElection (PAUSE) which dynamically selects a subset of users each round while ensuring bounded overall privacy leakage. We establish a theoretical analysis, systematically showing that the reward growth rate of PAUSE follows that of the best-known rate in MAB literature. To address the complexity overhead of active user selection, we propose a simulated annealing-based relaxation of PAUSE and analyze its ability to approximate the reward-maximizing policy under reduced complexity. We numerically validate the privacy leakage, associated improved latency, and accuracy gains of our methods for the federated training in various scenarios.",http://arxiv.org/abs/2503.13173v1,"devices, edge, learning, federated, fl",Quantum Machine Learning,1505,2004
HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of Imitation Learning,"Wensheng Wang, Ning Tan","The acquisition of large-scale and diverse demonstration data are essential for improving robotic imitation learning generalization. However, generating such data for complex manipulations is challenging in real-world settings. We introduce HybridGen, an automated framework that integrates Vision-Language Model (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first, VLM to parse expert demonstrations, decomposing tasks into expert-dependent (object-centric pose transformations for precise control) and plannable segments (synthesizing diverse trajectories via path planning); second, pose transformations substantially expand the first-stage data. Crucially, HybridGen generates a large volume of training data without requiring specific data formats, making it broadly applicable to a wide range of imitation learning algorithms, a characteristic which we also demonstrate empirically across multiple algorithms. Evaluations across seven tasks and their variants demonstrate that agents trained with HybridGen achieve substantial performance and generalization gains, averaging a 5% improvement over state-of-the-art methods. Notably, in the most challenging task variants, HybridGen achieves significant improvement, reaching a 59.7% average success rate, significantly outperforming Mimicgen's 49.5%. These results demonstrating its effectiveness and practicality.",http://arxiv.org/abs/2503.13171v1,"data, scale, demonstration, imitation, acquisition",Machine Learning & AI in Quantum,401,2016
Efficient Imitation Under Misspecification,"Nicolas Espinosa-Dice, Sanjiban Choudhury, Wen Sun, Gokul Swamy","Interactive imitation learning (IL) is a powerful paradigm for learning to make sequences of decisions from an expert demonstrating how to perform a task. Prior work in efficient imitation learning has focused on the realizable setting, where the expert's policy lies within the learner's policy class (i.e. the learner can perfectly imitate the expert in all states). However, in practice, perfect imitation of the expert is often impossible due to differences in state information and action space expressiveness (e.g. morphological differences between robots and humans.) In this paper, we consider the more general misspecified setting, where no assumptions are made about the expert policy's realizability. We introduce a novel structural condition, reward-agnostic policy completeness, and prove that it is sufficient for interactive IL algorithms to efficiently avoid the quadratically compounding errors that stymie offline approaches like behavioral cloning. We address an additional practical constraint-the case of limited expert data-and propose a principled method for using additional offline data to further improve the sample-efficiency of interactive IL algorithms. Finally, we empirically investigate the optimal reset distribution in efficient IL under misspecification with a suite of continuous control tasks.",http://arxiv.org/abs/2503.13162v1,"imitation, il, paradigm, learning, sequences","Quantum Machine Learning, Machine Learning & AI in Quantum",4524,2023
Photon information efficiency limits in deep-space optical communications,"M. Jarzyna, L. Kunz, W. Zwolinski, M. Jachura, K. Banaszek","Deep-space optical communication links operate under severely limited signal power, approaching the photon-starved regime which requires a receiver capable of measuring individual incoming photons. This makes the photon information efficiency (PIE), i.e. the number of bits that can be retrieved from a single received photon, a relevant figure of merit to characterize data rates achievable in deep-space scenarios. Here we review theoretical PIE limits assuming a scalable modulation format, such as pulse position modulation (PPM), combined with a photon counting direct detection receiver. For unrestricted signal bandwidth, the attainable PIE is effectively limited by the background noise acquired by the propagating optical signal. The actual PIE limit depends on the effectiveness of the noise rejection mechanism implemented at the receiver, which can be improved by the nonlinear optical technique of quantum pulse gating. Further enhancement is possible by resorting to photon number resolved detection, which improves discrimination of PPM pulses against weak background noise. The results are compared with the ultimate quantum mechanical PIE limit implied by the Gordon-Holevo capacity bound, which takes into account general modulation formats as well as any physically permitted measurement techniques.",http://arxiv.org/abs/2503.13161v1,"signal, links, space, communication, power",Quantum Computing & Information,4484,2016
Laplace-Net: Learning Dynamical Systems with External Forcing,"Bernd Zimmering, Cec?lia Coelho, Vaibhav Gupta, Maria Maleshkova, Oliver Niggemann","Modelling forced dynamical systems - where an external input drives the system state - is critical across diverse domains such as engineering, finance, and the natural sciences. In this work, we propose Laplace-Net, a decoupled, solver-free neural framework for learning forced and delay-aware systems. It leverages a Laplace transform-based approach to decompose internal dynamics, external inputs, and initial values into established theoretical concepts, enhancing interpretability. Laplace-Net promotes transferability since the system can be rapidly re-trained or fine-tuned for new forcing signals, providing flexibility in applications ranging from controller adaptation to long-horizon forecasting. Experimental results on eight benchmark datasets - including linear, non-linear, and delayed systems - demonstrate the method's improved accuracy and robustness compared to state-of-the-art approaches, particularly in handling complex and previously unseen inputs.",http://arxiv.org/abs/2503.13158v1,"systems, modelling, state, system, input",Quantum Machine Learning,3571,2016
Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs,"Jasmin Wachter, Michael Radloff, Maja Smolej, Katharina Kinder-Kurlanda","We introduce an Item Response Theory (IRT)-based framework to detect and quantify socioeconomic bias in large language models (LLMs) without relying on subjective human judgments. Unlike traditional methods, IRT accounts for item difficulty, improving ideological bias estimation. We fine-tune two LLM families (Meta-LLaMa 3.2-1B-Instruct and Chat- GPT 3.5) to represent distinct ideological positions and introduce a two-stage approach: (1) modeling response avoidance and (2) estimating perceived bias in answered responses. Our results show that off-the-shelf LLMs often avoid ideological engagement rather than exhibit bias, challenging prior claims of partisanship. This empirically validated framework enhances AI alignment research and promotes fairer AI governance.",http://arxiv.org/abs/2503.13149v1,"response, bias, theory, framework, item",Machine Learning & AI in Quantum,2288,2001
High-entropy Advantage in Neural Networks' Generalizability,"Entao Yang, Xiaotian Zhang, Yue Shang, Ge Zhang","While the 2024 Nobel Prize in Physics ignites a worldwide discussion on the origins of neural networks and their foundational links to physics, modern machine learning research predominantly focuses on computational and algorithmic advancements, overlooking a picture of physics. Here we introduce the concept of entropy into neural networks by reconceptualizing them as hypothetical physical systems where each parameter is a non-interacting 'particle' within a one-dimensional space. By employing a Wang-Landau algorithms, we construct the neural networks' (with up to 1 million parameters) entropy landscapes as functions of training loss and test accuracy (or loss) across four distinct machine learning tasks, including arithmetic question, real-world tabular data, image recognition, and language modeling. Our results reveal the existence of \textit{entropy advantage}, where the high-entropy states generally outperform the states reached via classical training optimizer like stochastic gradient descent. We also find this advantage is more pronounced in narrower networks, indicating a need of different training optimizers tailored to different sizes of neural networks.",http://arxiv.org/abs/2503.13145v1,"origins, physics, discussion, prize, nobel",Quantum Machine Learning,3109,2001
Negative Currents in Fabry-P?rot Cavities are Caused by Interfering Paths,"Mrinmoyee Saha, Luca Horray, Pedro Portugal, Christian Flindt","The time-dependent electric current in a Fabry-P\'erot cavity can turn negative even if the time-dependent voltage is always positive. Here we present an analytic theory of this surprising phenomenon, showing that it is a purely quantum mechanical effect. It only occurs at low temperatures, and it is caused by interferences between paths through the cavity with different numbers of round trips. We provide realistic parameters for observing the negative currents in an experiment and show that a similar phenomenon is expected for the heat current, which may also turn negative.",http://arxiv.org/abs/2503.13144v1,"current, cavity, fabry, time, p\'erot",Quantum Computing & Information,210,2021
Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding,"Weiyu Guo, Ziyang Chen, Shaoguang Wang, Jianxiang He, Yijie Xu, Jinhui Ye, Ying Sun, Hui Xiong","Understanding long video content is a complex endeavor that often relies on densely sampled frame captions or end-to-end feature selectors, yet these techniques commonly overlook the logical relationships between textual queries and visual elements. In practice, computational constraints necessitate coarse frame subsampling, a challenge analogous to ``finding a needle in a haystack.'' To address this issue, we introduce a semantics-driven search framework that reformulates keyframe selection under the paradigm of Visual Semantic-Logical Search. Specifically, we systematically define four fundamental logical dependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute dependency, and 4) causal order. These relations dynamically update frame sampling distributions through an iterative refinement process, enabling context-aware identification of semantically critical frames tailored to specific query requirements. Our method establishes new SOTA performance on the manually annotated benchmark in key-frame selection metrics. Furthermore, when applied to downstream video question-answering tasks, the proposed approach demonstrates the best performance gains over existing methods on LongVideoBench and Video-MME, validating its effectiveness in bridging the logical gap between textual queries and visual-temporal reasoning. The code will be publicly available.",http://arxiv.org/abs/2503.13139v1,"endeavor, frame, content, captions, video",Machine Learning & AI in Quantum,4885,2022
Gravito-turbulent bi-fluid protoplanetary discs: 1. An analytical perspective to stratification,"S. Rendon Restrepo, U. Ziegler, M. Villenave, O. Gressel","Context. In Class 0/I and the outskirts of Class II circumstellar discs, the self-gravity of gas significantly affects the disc's vertical hydrostatic equilibrium. The contribution of dust, whose measured mass is still uncertain, could influence this equilibrium. Aims. We aim to formulate and solve approximately the equations governing the hydrostatic equilibrium of a self-gravitating disc composed of gas and dust. Particularly, we aim to provide a fully consistent treatment of turbulence and gravity, affecting almost symmetrically gas and dust. Observationally, we study the possibility of indirectly measuring disc masses through gas layering and dust settling measurements. Methods. We used analytical methods to approximate the solution of the 1D Liouville equation with additional non-linearities governing the stratification of a self-gravitating protoplanetary disc. The findings were verified numerically and validated through physical interpretation. Results. For a constant vertical stopping time profile, we discovered a nearly exact layering solution valid across all self-gravity regimes for gas and dust. From first principles, we defined the Toomre parameter of a bi-fluid system as the harmonic average of its constituents' Toomre parameters. Based on these findings, we propose a method to estimate disc mass through gas or dust settling observations. We introduce a generic definition of the dust-to-gas scale height, applicable to complex profiles. We also identified new exact solutions for benchmarking self-gravity solvers in numerical codes. Conclusions. The hydrostatic equilibrium of a gas/dust mixture is governed by their Toomre parameters and effective relative temperature. This equilibrium could be used for measuring disc masses, improving our understanding of disc settling and gravitational collapse, and enhancing the computation of self-gravity in thin disc simulations.",http://arxiv.org/abs/2503.13136v1,"class, context, ii, outskirts",Mathematical & Theoretical Quantum Physics,3114,2004
Accelerating large-scale linear algebra using variational quantum imaginary time evolution,"Willie Aboumrad, Daiwei Zhu, Claudio Girotto, Fran?ois-Henry Rouet, Jezer Jojo, Robert Lucas, Jay Pathak, Ananth Kaushik, Martin Roetteler","Graph partitioning techniques enhance the efficiency of solving large-scale linear systems in the context of Finite Element Analysis (FEA). Even for systems of linear equations that are highly sparse, their direct solution via factorization methods, such as LU or Cholesky decomposition, is computationally expensive due to the introduction of non-zero elements, or ``fill-in.'' We introduce a quantum approach to the graph partitioning problem based on the variational quantum imaginary time evolution algorithm (VarQITE), allowing to solve the combinatorial optimization problem of reordering of sparse matrices to minimize the fill-in. We develop a hybrid quantum/classical pipeline to accelerate Finite Element solvers by integrating the VarQITE algorithm into the production workflow of Ansys' industrial software LS-DYNA. This allows to study multiple different types of FEA problems, ranging from mechanical engineering to computational fluid dynamics.   We prove out that VarQITE positively impacts LS-DYNA workflows by measuring the wall-clock time to solution of FEA problems when compared against the classical heuristic graph partitioning solver in LS-DYNA. The selected instances cover a range of FEA problems, including simulation of blood pumps, roof crushing of cars, and vibration analysis of cars. We report performance results for our hybrid quantum-accelerated workflow on FEA meshes of up to 5.9M vertices and 55 million edges. We find that the wall clock time of the heuristics solutions used in the industry-grade solver is improved by up to 12\%. We also execute the VarQITE algorithm on quantum hardware (IonQ Aria and IonQ Forte) and find that the results are comparable to noiseless and noisy simulations. Finally, we introduce a hybrid technique for post-processing the found solutions with classical refinement heuristics such as Fiduccia-Mattheyses.",http://arxiv.org/abs/2503.13128v1,"techniques, scale, efficiency, linear, graph",Quantum Computing & Information,4608,2000
MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network,"Xintian Yuan, Yunke Ao, Boqi Chen, Philipp Fuernstahl","Simulating the complex interactions between soft tissues and rigid anatomy is critical for applications in surgical training, planning, and robotic-assisted interventions. Traditional Finite Element Method (FEM)-based simulations, while accurate, are computationally expensive and impractical for real-time scenarios. Learning-based approaches have shown promise in accelerating predictions but have fallen short in modeling soft-rigid interactions effectively. We introduce MIXPINN, a physics-informed Graph Neural Network (GNN) framework for mixed-material simulations, explicitly capturing soft-rigid interactions using graph-based augmentations. Our approach integrates Virtual Nodes (VNs) and Virtual Edges (VEs) to enhance rigid body constraint satisfaction while preserving computational efficiency. By leveraging a graph-based representation of biomechanical structures, MIXPINN learns high-fidelity deformations from FEM-generated data and achieves real-time inference with sub-millimeter accuracy. We validate our method in a realistic clinical scenario, demonstrating superior performance compared to baseline GNN models and traditional FEM methods. Our results show that MIXPINN reduces computational cost by an order of magnitude while maintaining high physical accuracy, making it a viable solution for real-time surgical simulation and robotic-assisted procedures.",http://arxiv.org/abs/2503.13123v1,"interactions, applications, tissues, training, anatomy",Machine Learning & AI in Quantum,2464,2000
Production of biogas from invasive weed (Striga hermonthica) through anaerobic co-digestion with cow manure,Mathewos Fikre ,"The unsustainability of conventional energy resources and their associated environmental pollutions made renewable energy the prime need of present time. Therefore, the research was conducted to investigate the production of biogas from Striga hermonthica co-digested with cow manure through anaerobic digestion with five treatment mix ratios were evaluated under mesophilic conditions (38?C) using batch digesters in the Botanical laboratory of Haramaya University for 30 days of fermentation. In all treatments, physico-chemical parameters such as total solid, volatile solid, organic carbon, nitrogen, pH value and percent of moisture content were measured before and after anaerobic digestion. The results were indicated that, highest pH value (7.27 ) was observed in 10% total solid with 100% cow manure, whereas the lowest pH values (6.37) was observed in 100% Striga hermonthica with the same percentage of total solid content. Comparison of pH values between before and after anaerobic digestion showed that pH values were significantly increased after anaerobic digestion for all treatments. Similarly, maximum value of % total solid and volatile solid was recorded in 100% cow manure with 10% total solid content. In addition to this, carbon to nitrogen ratios were analyzed, the results were revealed that highest carbon to nitrogen ratio was observed in 10% total solid with 100% Striga hermonthica and lowest value in 6% total solid with mix ratio of 50% cow manure +50% Striga hermonthica. In this experimental study the result showed that co-digested substrates of the three mix ratios produced higher amount of biogas than the two sole alone. Among the different proportion of the total solid, 10%, total solid with mix ratio of 25% cow manure +75% Striga hermonthica showed the highest daily mean cumulative biogas production (2150ml) than all other treatments. Over all the results of this study indicate that the increase in biogas yield and reduction in volatile solids and total solids can be significantly enhanced when cow manure is co-digested with Striga hermonthica in 25%:75% mix ratio.",https://afribary.com/works/production-of-biogas-from-invasive-weed-striga-hermonthica-through-anaerobic-co-digestion-with-cow-manure,"renewable energy, biogas production, anaerobic digestion, striga hermonthica, cow manure, co-digestion, mesophilic conditions, batch digesters, haramaya university, physico-chemical parameters, total solid, volatile solid, organic carbon, carbon to nitrogen ratio, c/n ratio, pH value, moisture content, environmental sustainability, fermentation process, biogas yield, cumulative biogas production, waste management, renewable resource utilization, green energy, energy sustainability, methane production, biofuel, organic waste, digestion efficiency, nutrient composition, biomass conversion, gas production rate, microbial activity, fermentation efficiency, substrate degradation, solid waste management, alternative energy, greenhouse gas reduction, anaerobic microbial process, digestion kinetics, organic matter breakdown, bioenergy, sustainable agriculture, energy recovery, methane yield, biodegradability, feedstock composition, digestion performance, waste-to-energy, biofertilizer, carbon balance",Environmental Engineering,60,2018
Bridging Computational Challenges with Controllable Quantum Systems,"I. M. Georgescu, S. Ashhab, Franco Nori","Simulating quantum mechanics is known to be a difficult computational problem, especially when dealing with large systems. However, this difficulty may be overcome by using some controllable quantum system to study another less controllable or accessible quantum system, i.e., quantum simulation. Quantum simulation promises to have applications in the study of many problems in, e.g., condensed-matter physics, high-energy physics, atomic physics, quantum chemistry and cosmology. Quantum simulation could be implemented using quantum computers, but also with simpler, analog devices that would require less control, and therefore, would be easier to construct. A number of quantum systems such as neutral atoms, ions, polar molecules, electrons in semiconductors, superconducting circuits, nuclear spins and photons have been proposed as quantum simulators. This review outlines the main theoretical and experimental aspects of quantum simulation and emphasizes some of the challenges and promises of this fast-growing field.",https://arxiv.org/abs/1308.6253,"quantum simulation, quantum mechanics, computational complexity, quantum systems, condensed-matter physics, high-energy physics, atomic physics, quantum chemistry, cosmology, quantum computing, analog quantum simulation, digital quantum simulation, quantum simulators, neutral atoms, trapped ions, polar molecules, superconducting circuits, nuclear spins, photons, quantum control, quantum algorithms, experimental quantum physics, theoretical quantum physics, quantum information science, quantum hardware, quantum coherence, quantum entanglement, quantum many-body systems, simulation of quantum materials, quantum phase transitions, quantum field theory",Quantum Simulation,50,2020
"Stakeholders??diverging interests and emerging resource use conflicts in apiculture in West Usambara Mountains, Tanzania","Kimaro D. N., Sinyangwe J., Mbeyale G. E., Kajembe G. C., Mogaka Hezron R.","tudy was conducted in West Usambara Mountains, Tanzania to assess stakeholders diverging interests and emerging resource use conflicts in apiculture with respect to natural resource management (NRM) by local communities. The study aimed at generating knowledge base for effective governance of NRM by farmers from which lessons could be drawn for guiding appropriate NRM. Participatory Rural Appraisal (PRA) tools including focused group discussion, questionnaire survey and participant observation were used for data collection from 98 respondents randomly selected. Data collected were analysed using descriptive and inferential statistical analyses. Results show that majority of individual small scale farmers (73%) were driven by social economic interests than NRM. On the other hand, farmers??groups (10%) showed high interest in both economic and conservation of natural resources followed by faith based organisations (FBOs) (7%). Stakeholders??diverging interests in apiculture were significantly influenced by educational level (p=0.010); household size (p=0.006); marital status (p=0.011) and major economic activities (p=0.029). The most prevalent conflicts in the study area were between farmers practising apiculture and fellow farmers (74%) followed by neighbours (16%). The study demonstrated that for small scale farmers to engage in NRM, economic interest is vital. Recommendations on areas of further intervention are given.",https://afribary.com/works/stakeholders-diverging-interests-and-emerging-resource-use-conflicts-in-apiculture-in-west-usambara-mountains-tanzania-2,"natural resource management, NRM, sustainable resource use, environmental governance, conservation, apiculture, ecosystem management, biodiversity conservation, land use conflicts, participatory rural appraisal, stakeholder engagement, socio-environmental conflicts, community-based resource management, sustainable agriculture, ecological sustainability, rural development, environmental policy, small-scale farming, environmental impact assessment, watershed management, deforestation, habitat preservation, ecological restoration, environmental planning, sustainable livelihoods, human-environment interaction, socio-economic factors in conservation, environmental sustainability, climate change adaptation, ecosystem services, conflict resolution in resource management",Environmental Engineering,80,2024
